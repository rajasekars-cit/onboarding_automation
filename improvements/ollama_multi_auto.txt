# FILE: run.py
# ==============================================================================
# UPDATED: Imports MAX_WORKER_THREADS from the config module.
# ==============================================================================
import time
import logging
import queue
import threading
from concurrent.futures import ThreadPoolExecutor
from app.main import run_onboarding_process
from app.services.db_service import setup_database, get_all_active_configurations
from app.config import get_static_config

# --- Basic Configuration ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(threadName)s - %(module)s - %(message)s')

# --- Thread Pool Configuration ---
# This is now loaded from config, but we need a local reference
WORK_QUEUE = queue.Queue()

def worker_thread():
    """The consumer function that each thread in the pool will run."""
    logging.info("Worker thread started and waiting for tasks.")
    while True:
        try:
            # Get a configuration from the queue to process
            config = WORK_QUEUE.get()
            if config is None:  # Sentinel value to stop the thread
                break
            
            config_id = config.get('config_id', 'unknown')
            logging.info(f"Worker picked up task for config: {config_id}")
            run_onboarding_process(config)
            
        except Exception as e:
            logging.error(f"Error in worker thread: {e}", exc_info=True)
        finally:
            WORK_QUEUE.task_done()

def producer_thread(static_config):
    """
    The producer function that runs on a schedule to check the DB
    and add tasks to the queue for the workers.
    """
    while True:
        try:
            logging.info("Producer thread waking up to schedule tasks...")
            active_configs = get_all_active_configurations()
            
            if not active_configs:
                logging.info("Producer found no active configurations.")
            else:
                logging.info(f"Producer found {len(active_configs)} active configurations to queue.")
                for dynamic_config in active_configs:
                    full_config = {**static_config, **dynamic_config}
                    WORK_QUEUE.put(full_config)
            
            # Sleep for the main scheduling interval (e.g., 1 minute)
            schedule_interval_seconds = int(static_config.get('SCHEDULE_MINUTES', 5)) * 60
            time.sleep(schedule_interval_seconds)

        except Exception as e:
            logging.error(f"Error in producer thread: {e}", exc_info=True)
            time.sleep(60) # Wait a minute before retrying on error

if __name__ == "__main__":
    logging.info("Initializing multi-system onboarding application with Thread Pool...")
    
    # 1. Load static configuration from the .env file
    static_config = get_static_config()
    MAX_WORKER_THREADS = static_config['MAX_WORKER_THREADS']
    
    # 2. Set up the database tables
    logging.info("Verifying database setup...")
    setup_database()

    # 3. Create and start the fixed-size thread pool
    with ThreadPoolExecutor(max_workers=MAX_WORKER_THREADS, thread_name_prefix='Worker') as executor:
        for _ in range(MAX_WORKER_THREADS):
            executor.submit(worker_thread)

        # 4. Start the producer thread
        producer = threading.Thread(target=producer_thread, args=(static_config,), name="Producer")
        producer.daemon = True
        producer.start()
        
        # 5. Keep the main thread alive
        try:
            producer.join()
        except KeyboardInterrupt:
            logging.info("Application shutting down...")
            # Signal worker threads to stop
            for _ in range(MAX_WORKER_THREADS):
                WORK_QUEUE.put(None)

# ==============================================================================
# FILE: app/config.py
# ==============================================================================
# UPDATED: Simplified to only load static config and return it.
# ==============================================================================
import os
import logging
from dotenv import load_dotenv

load_dotenv()

def get_static_config():
    """
    Loads configuration ONLY from environment variables and returns it as a dictionary.
    """
    logging.info("Loading static configuration from .env file...")
    config = {}
    # Static config from .env file
    config['SCHEDULE_MINUTES'] = int(os.getenv("SCHEDULE_MINUTES", 5))
    config['MAX_WORKER_THREADS'] = int(os.getenv("MAX_WORKER_THREADS", 10))
    config['IMAP_SERVER'] = os.getenv("IMAP_SERVER")
    config['SMTP_SERVER'] = os.getenv("SMTP_SERVER")
    config['SMTP_PORT'] = int(os.getenv("SMTP_PORT", 587))
    config['EMAIL_USER'] = os.getenv("EMAIL_USER")
    config['EMAIL_PASS'] = os.getenv("EMAIL_PASS")
    config['INITIAL_LOOKBACK_DAYS'] = int(os.getenv("INITIAL_LOOKBACK_DAYS", 1))
    config['REMINDER_THRESHOLD_HOURS'] = int(os.getenv("REMINDER_THRESHOLD_HOURS", 24))
    
    # Ollama configuration from .env
    config['OLLAMA_HOST'] = os.getenv("OLLAMA_HOST", "http://localhost:11434")
    config['OLLAMA_MODEL'] = os.getenv("OLLAMA_MODEL", "llama3:8b")
        
    logging.info("Static configuration loaded successfully.")
    return config

# ==============================================================================
# FILE: app/main.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import logging
from app.services.email_service import process_mailbox, process_pending_reminders

def run_onboarding_process(config: dict):
    """
    The main job for a SINGLE onboarding configuration.
    This function is executed by a worker thread.
    """
    config_id = config.get('config_id', 'unknown')
    logging.info(f"--- [{config_id}] Starting job cycle ---")
    
    logging.info(f"--- [{config_id}] Step 1: Checking for new emails...")
    try:
        process_mailbox(config)
        logging.info(f"--- [{config_id}] Finished processing mailbox.")
    except Exception as e:
        logging.error(f"--- [{config_id}] An unexpected error occurred during mailbox processing: {e}", exc_info=True)
        
    logging.info(f"--- [{config_id}] Step 2: Checking for pending requests...")
    try:
        process_pending_reminders(config)
        logging.info(f"--- [{config_id}] Finished processing pending reminders.")
    except Exception as e:
        logging.error(f"--- [{config_id}] An unexpected error occurred during reminder processing: {e}", exc_info=True)

    logging.info(f"--- [{config_id}] Job cycle finished ---")


# ==============================================================================
# FILE: app/services/email_service.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import logging
import re
from datetime import datetime

from app.services import db_service
from app.services.ai_service import analyze_email

def build_search_query(last_check_timestamp, config):
    """Builds a dynamic, efficient IMAP search query."""
    search_date = datetime.fromisoformat(last_check_timestamp).strftime('%d-%b-%Y')
    criteria = [f'(SINCE "{search_date}")']
    addresses_to_check = config.get('approvers', []) + [config.get('support_email')]
    address_criteria = [f'(OR (TO "{addr}") (CC "{addr}"))' for addr in addresses_to_check if addr]
    if address_criteria:
        criteria.append(f"(OR {' '.join(address_criteria)})")
    return " ".join(criteria)

def get_email_body(msg):
    """Extracts the text body from an email message."""
    if msg.is_multipart():
        for part in msg.walk():
            if part.get_content_type() == "text/plain" and "attachment" not in str(part.get("Content-Disposition")):
                try: return part.get_payload(decode=True).decode()
                except: return part.get_payload(decode=True).decode('latin-1')
    else:
        try: return msg.get_payload(decode=True).decode()
        except: return msg.get_payload(decode=True).decode('latin-1')
    return ""

def process_mailbox(config):
    """Connects to the mailbox, fetches emails using a smart query, and processes them."""
    config_id = config['config_id']
    last_check_timestamp = db_service.get_last_check_time(config_id, config)
    
    try:
        mail = imaplib.IMAP4_SSL(config['IMAP_SERVER'])
        mail.login(config['EMAIL_USER'], config['EMAIL_PASS'])
        mail.select("inbox")

        search_criteria = build_search_query(last_check_timestamp, config)
        logging.info(f"[{config_id}] Searching for emails with criteria: {search_criteria}")
        status, messages = mail.uid('search', None, search_criteria)
        if status != "OK":
            logging.error(f"[{config_id}] Failed to search for emails."); return

        all_uids = messages[0].split()
        if not all_uids:
            logging.info(f"[{config_id}] No new relevant emails found.")
        else:
            processed_uids = db_service.get_processed_uids(all_uids)
            new_uids = [uid for uid in all_uids if uid.decode() not in processed_uids]
            
            if not new_uids:
                logging.info(f"[{config_id}] No new emails to process after filtering already processed UIDs.")
            else:
                logging.info(f"[{config_id}] Found {len(new_uids)} new email(s) to process.")
                for uid in new_uids:
                    try:
                        status, msg_data = mail.uid('fetch', uid, "(RFC822)")
                        if status != "OK": continue

                        msg = email.message_from_bytes(msg_data[0][1])
                        subject, _ = decode_header(msg["Subject"])[0]
                        if isinstance(subject, bytes): subject = subject.decode()
                        from_ = msg.get("From")
                        body = get_email_body(msg)
                        thread_id = msg.get('References', msg.get('In-Reply-To', msg.get('Message-ID'))).strip()

                        analysis = analyze_email(subject, body, config)
                        if not analysis:
                            db_service.mark_uid_as_processed(uid.decode()); continue
                            
                        intent = analysis.get('intent')
                        
                        if intent == 'new_request':
                            user_email = analysis.get('user_email')
                            if user_email: db_service.create_onboarding_request(thread_id, user_email)
                        
                        elif intent == 'approval':
                            request = db_service.get_request_by_thread_id(thread_id)
                            if not request:
                                logging.warning(f"[{config_id}] Received an approval for an unknown thread ID: {thread_id}. Skipping.")
                            else:
                                approver_email = (re.search(r'<(.+?)>', from_) or re.search(r'[\w\.-]+@[\w\.-]+', from_)).group(0).strip('<>')
                                effective_approvers = db_service.get_effective_approvers(request, config)
                                if approver_email in effective_approvers:
                                    user_to_onboard = request['user_to_onboard_email']
                                    all_approved = db_service.add_approval_to_request(thread_id, approver_email, config)
                                    if all_approved:
                                        db_service.update_user_access(user_to_onboard)
                                        db_service.update_request_status(thread_id, 'completed', f"Access granted for {user_to_onboard}.")
                                        send_confirmation_email(user_to_onboard, thread_id, config)
                                else:
                                    logging.warning(f"[{config_id}] Received approval from unauthorized user: {approver_email} for thread {thread_id}")

                        elif intent == 'out_of_office':
                            delegate_email = analysis.get('delegate_email')
                            original_approver = (re.search(r'<(.+?)>', from_) or re.search(r'[\w\.-]+@[\w\.-]+', from_)).group(0).strip('<>')
                            if delegate_email and original_approver in config['approvers']:
                                request = db_service.get_request_by_thread_id(thread_id)
                                if request:
                                    db_service.add_delegated_approver(thread_id, delegate_email, original_approver)
                                    send_delegation_request_email(delegate_email, request, config)
                                else:
                                    logging.warning(f"[{config_id}] Received OOO for an unknown thread: {thread_id}")

                        db_service.mark_uid_as_processed(uid.decode())

                    except Exception as e:
                        logging.error(f"[{config_id}] Error processing email UID {uid.decode()}: {e}", exc_info=True)
        
        mail.logout()
        db_service.update_last_check_time(config_id, datetime.now().isoformat())

    except Exception as e:
        logging.error(f"[{config_id}] Failed to connect to or process mailbox: {e}", exc_info=True)

def send_delegation_request_email(delegate_email, request, config):
    """Sends an email to a delegated approver asking for their action."""
    user_to_onboard = request['user_to_onboard_email']
    thread_id = request['request_thread_id']
    logging.info(f"Sending delegation request to {delegate_email} for user {user_to_onboard}")

    subject = f"ACTION REQUIRED: Delegated Approval for Onboarding {user_to_onboard}"
    body = f"""Hello,\n\nAn onboarding request for the user '{user_to_onboard}' requires approval. The primary approver is out of office, and you have been named as the delegate for this action.\n\nPlease review the request and reply to this email with 'Approved' or 'Rejected'.\n\nThank you,\nAutomation Bot\n\n(Original Reference ID: {thread_id})"""
    msg = MIMEMultipart()
    msg['From'] = config['EMAIL_USER']
    msg['To'] = delegate_email
    msg['Cc'] = config['support_email']
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'plain'))
    
    try:
        with smtplib.SMTP(config['SMTP_SERVER'], config['SMTP_PORT']) as server:
            server.starttls()
            server.login(config['EMAIL_USER'], config['EMAIL_PASS'])
            server.send_message(msg)
            logging.info(f"Successfully sent delegation request to {delegate_email}")
            db_service.update_request_status(thread_id, 'pending_approval', f"Approval delegated to {delegate_email}.")
    except Exception as e:
        logging.error(f"Failed to send delegation email: {e}", exc_info=True)

def process_pending_reminders(config):
    """Fetches stale pending requests and sends reminder emails."""
    config_id = config['config_id']
    pending_requests = db_service.get_pending_requests_for_reminder(config)
    if not pending_requests:
        logging.info(f"[{config_id}] No pending requests found that require a reminder.")
        return
    
    logging.info(f"[{config_id}] Found {len(pending_requests)} pending request(s) requiring a reminder.")
    for request in pending_requests:
        try:
            send_reminder_email(request, config)
        except Exception as e:
            logging.error(f"[{config_id}] Failed to send reminder for request ID {request['id']}: {e}", exc_info=True)

def send_confirmation_email(user_email, thread_id, config):
    """Sends the final confirmation email after successful onboarding."""
    logging.info(f"Preparing to send confirmation email to {user_email}")
    subject = "Welcome! Your Access has been Granted"
    body = f"Hello,\n\nThis is an automated message to confirm that your account ({user_email}) has been successfully onboarded and access has been granted.\n\nBest regards,\nThe Support Team\n\n(Reference ID: {thread_id})"
    msg = MIMEMultipart()
    msg['From'] = config['EMAIL_USER']
    msg['To'] = user_email
    msg['Cc'] = ", ".join(config['approvers'] + [config['support_email']])
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'plain'))
    try:
        with smtplib.SMTP(config['SMTP_SERVER'], config['SMTP_PORT']) as server:
            server.starttls()
            server.login(config['EMAIL_USER'], config['EMAIL_PASS'])
            server.send_message(msg)
            logging.info(f"Successfully sent confirmation email to {user_email}")
            db_service.update_request_status(thread_id, 'completed', "Confirmation email sent successfully.")
    except Exception as e:
        logging.error(f"Failed to send confirmation email: {e}", exc_info=True)
        db_service.update_request_status(thread_id, 'error', f"Failed to send confirmation email: {e}")

def send_reminder_email(request, config):
    """Sends a reminder to approvers who have not yet approved a request."""
    user_to_onboard = request['user_to_onboard_email']
    missing_approvers = db_service.get_missing_approvers(request, config)

    if not missing_approvers:
        logging.warning(f"Request ID {request['id']} is pending but has no missing approvers. Skipping reminder.")
        return

    logging.info(f"Preparing to send reminder for {user_to_onboard} to: {', '.join(missing_approvers)}")
    subject = f"REMINDER: Approval Required for Onboarding {user_to_onboard}"
    body = f"Hello,\n\nThis is an automated reminder that your approval is required for the user onboarding request for:\n\nUser: {user_to_onboard}\n\nThis request is currently pending your action. Please reply to the original request with your approval.\n\nThank you,\nAutomation Bot\n\n(Original Reference ID: {request['request_thread_id']})"
    
    msg = MIMEMultipart()
    msg['From'] = config['EMAIL_USER']
    msg['To'] = ", ".join(missing_approvers)
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'plain'))
    
    try:
        with smtplib.SMTP(config['SMTP_SERVER'], config['SMTP_PORT']) as server:
            server.starttls()
            server.login(config['EMAIL_USER'], config['EMAIL_PASS'])
            server.send_message(msg)
            logging.info(f"Successfully sent reminder email for request ID {request['id']}")
            db_service.update_request_status(request['request_thread_id'], 'pending_approval', f"Reminder sent to: {', '.join(missing_approvers)}")
    except Exception as e:
        logging.error(f"Failed to send reminder email for request ID {request['id']}: {e}", exc_info=True)

# ==============================================================================
# FILE: app/services/db_service.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import psycopg2
import logging
import json
import os
from psycopg2.extras import DictCursor
from datetime import datetime, timedelta

def get_db_connection():
    """Establishes a connection to the PostgreSQL database."""
    try:
        conn = psycopg2.connect(
            dbname=os.getenv("DB_NAME"), user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASS"), host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT")
        )
        return conn
    except psycopg2.OperationalError as e:
        logging.error(f"Could not connect to PostgreSQL database: {e}"); raise

def setup_database():
    """Creates all necessary tables if they don't exist."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("CREATE TABLE IF NOT EXISTS users (id SERIAL PRIMARY KEY, email VARCHAR(255) UNIQUE NOT NULL, access_flag BOOLEAN DEFAULT FALSE, created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP);")
            cur.execute("CREATE TABLE IF NOT EXISTS onboarding_tracker (id SERIAL PRIMARY KEY, request_thread_id TEXT UNIQUE NOT NULL, user_to_onboard_email VARCHAR(255), status VARCHAR(50) NOT NULL DEFAULT 'new', approvals_received JSONB DEFAULT '[]'::jsonb, delegated_approvers JSONB DEFAULT '[]'::jsonb, last_activity_details TEXT, created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP, updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP);")
            cur.execute("CREATE TABLE IF NOT EXISTS app_state (key TEXT PRIMARY KEY, value TEXT NOT NULL);")
            cur.execute("CREATE TABLE IF NOT EXISTS processed_uids (uid TEXT PRIMARY KEY, processed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP);")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS configuration (
                    config_id TEXT PRIMARY KEY,
                    description TEXT,
                    support_email TEXT NOT NULL,
                    approvers JSONB NOT NULL,
                    is_active BOOLEAN DEFAULT TRUE
                );
            """)
            cur.execute("CREATE OR REPLACE FUNCTION trigger_set_timestamp() RETURNS TRIGGER AS $$ BEGIN NEW.updated_at = NOW(); RETURN NEW; END; $$ LANGUAGE plpgsql;")
            cur.execute("DROP TRIGGER IF EXISTS set_timestamp ON onboarding_tracker; CREATE TRIGGER set_timestamp BEFORE UPDATE ON onboarding_tracker FOR EACH ROW EXECUTE PROCEDURE trigger_set_timestamp();")
            conn.commit()
            logging.info("Database tables verified/created successfully.")
    except Exception as e: logging.error(f"Database setup failed: {e}")
    finally:
        if conn: conn.close()

def get_all_active_configurations():
    """Loads all active configuration profiles from the database."""
    conn = get_db_connection()
    configs = []
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("SELECT * FROM configuration WHERE is_active = TRUE;")
            for row in cur.fetchall():
                configs.append(dict(row))
    except Exception as e:
        logging.error(f"Could not load active configurations from database: {e}", exc_info=True)
    finally:
        if conn: conn.close()
    return configs

def get_effective_approvers(request, config):
    original_approvers = set(config['approvers'])
    delegations = request.get('delegated_approvers', [])
    if not delegations: return original_approvers
    delegation_map = {item['original']: item['delegate'] for item in delegations}
    effective_set = set()
    for approver in original_approvers:
        if approver in delegation_map: effective_set.add(delegation_map[approver])
        else: effective_set.add(approver)
    return effective_set

def get_missing_approvers(request, config):
    effective_approvers = get_effective_approvers(request, config)
    approvals_received = set(request.get('approvals_received', []))
    return list(effective_approvers - approvals_received)

def add_delegated_approver(thread_id, delegate_email, original_approver):
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            delegation_map = {"original": original_approver, "delegate": delegate_email}
            cur.execute("UPDATE onboarding_tracker SET delegated_approvers = delegated_approvers || %s::jsonb, last_activity_details = %s WHERE request_thread_id = %s;", (json.dumps(delegation_map), f"Approval for {original_approver} delegated to {delegate_email}", thread_id))
            conn.commit()
            logging.info(f"Added {delegate_email} as a delegated approver for {original_approver} on thread {thread_id}")
    except Exception as e: logging.error(f"Failed to add delegated approver for thread {thread_id}: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def add_approval_to_request(thread_id, approver_email, config):
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("UPDATE onboarding_tracker SET approvals_received = approvals_received || %s::jsonb, last_activity_details = %s WHERE request_thread_id = %s RETURNING *;", (json.dumps(approver_email), f"Approval received from {approver_email}", thread_id))
            updated_request = cur.fetchone()
            conn.commit()
            if not updated_request: return False
            effective_approvers = get_effective_approvers(updated_request, config)
            received_approvals = set(updated_request['approvals_received'])
            logging.info(f"Thread {thread_id[:15]}... | Effective: {effective_approvers} | Received: {received_approvals}")
            return effective_approvers.issubset(received_approvals)
    except Exception as e:
        logging.error(f"Failed to add approval for thread {thread_id}: {e}", exc_info=True)
        return False
    finally:
        if conn: conn.close()
    
def get_processed_uids(uids_to_check):
    if not uids_to_check: return set()
    uids_to_check_str = [uid.decode() if isinstance(uid, bytes) else uid for uid in uids_to_check]
    conn = get_db_connection()
    processed_uids = set()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT uid FROM processed_uids WHERE uid = ANY(%s);", (uids_to_check_str,))
            for row in cur.fetchall(): processed_uids.add(row[0])
    except Exception as e: logging.error(f"Failed to get processed UIDs: {e}", exc_info=True)
    finally:
        if conn: conn.close()
    return processed_uids

def mark_uid_as_processed(uid):
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("INSERT INTO processed_uids (uid) VALUES (%s) ON CONFLICT (uid) DO NOTHING;", (uid,))
            conn.commit()
    except Exception as e: logging.error(f"Failed to mark UID {uid} as processed: {e}", exc_info=True)
    finally:
        if conn: conn.close()
        
def get_last_check_time(config_id, config):
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            state_key = f"last_check_timestamp_{config_id}"
            cur.execute("SELECT value FROM app_state WHERE key = %s;", (state_key,))
            result = cur.fetchone()
            if result: return result[0]
            else:
                initial_time = (datetime.now() - timedelta(days=config['INITIAL_LOOKBACK_DAYS'])).isoformat()
                logging.info(f"[{config_id}] No last check timestamp found in DB. Using initial lookback: {initial_time}")
                return initial_time
    except Exception as e:
        logging.error(f"Failed to get last check time for {config_id}: {e}", exc_info=True)
        return (datetime.now() - timedelta(days=1)).isoformat()
    finally:
        if conn: conn.close()

def update_last_check_time(config_id, timestamp_iso):
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            state_key = f"last_check_timestamp_{config_id}"
            cur.execute("INSERT INTO app_state (key, value) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value;", (state_key, timestamp_iso))
            conn.commit()
            logging.info(f"[{config_id}] Updated last check timestamp to: {timestamp_iso}")
    except Exception as e: logging.error(f"Failed to update last check time for {config_id}: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def get_pending_requests_for_reminder(config):
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            query = "SELECT * FROM onboarding_tracker WHERE status = 'pending_approval' AND updated_at < NOW() - INTERVAL '%s hours'"
            cur.execute(query, (config['REMINDER_THRESHOLD_HOURS'],))
            return cur.fetchall()
    except Exception as e:
        logging.error(f"Failed to get pending requests: {e}", exc_info=True)
        return []
    finally:
        if conn: conn.close()

def create_onboarding_request(thread_id, user_email):
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("INSERT INTO onboarding_tracker (request_thread_id, user_to_onboard_email, status, last_activity_details) VALUES (%s, %s, %s, %s) ON CONFLICT (request_thread_id) DO NOTHING;", (thread_id, user_email, 'pending_approval', f"New onboarding request received for {user_email}."))
            conn.commit()
            if cur.rowcount > 0: logging.info(f"New onboarding request created for {user_email} with thread ID {thread_id[:15]}...")
            else: logging.info(f"Onboarding request for thread ID {thread_id[:15]}... already exists.")
    except Exception as e: logging.error(f"Failed to create onboarding request: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def get_request_by_thread_id(thread_id):
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("SELECT * FROM onboarding_tracker WHERE request_thread_id = %s;", (thread_id,))
            return cur.fetchone()
    except Exception as e:
        logging.error(f"Failed to get request for thread {thread_id}: {e}", exc_info=True)
        return None
    finally:
        if conn: conn.close()

def update_request_status(thread_id, status, details):
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("UPDATE onboarding_tracker SET status = %s, last_activity_details = %s WHERE request_thread_id = %s;", (status, details, thread_id))
            conn.commit()
            logging.info(f"Updated status for thread {thread_id[:15]}... to '{status}'")
    except Exception as e: logging.error(f"Failed to update request status: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def update_user_access(user_email):
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT id FROM users WHERE email = %s;", (user_email,))
            if cur.fetchone() is None:
                logging.info(f"User {user_email} not found. Creating new user record.")
                cur.execute("INSERT INTO users (email) VALUES (%s);", (user_email,))
            cur.execute("UPDATE users SET access_flag = TRUE WHERE email = %s;", (user_email,))
            conn.commit()
            logging.info(f"Successfully updated access_flag for user {user_email}")
    except Exception as e: logging.error(f"Failed to update user access: {e}", exc_info=True)
    finally:
        if conn: conn.close()

# ==============================================================================
# FILE: app/services/ai_service.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import logging
import json
import re
import ollama

# Define the client variable at the module level, but don't initialize it yet.
client = None

def analyze_email(subject, body, config):
    """
    Uses a local Ollama model to classify email intent and extract entities.
    """
    global client
    
    # Initialize the client the first time the function is called.
    if client is None:
        logging.info(f"Initializing Ollama client with host: {config['OLLAMA_HOST']}")
        client = ollama.Client(host=config['OLLAMA_HOST'])

    full_content = f"Subject: {subject}\n\nBody:\n{body}"
    full_content = re.sub(r'\s+', ' ', full_content).strip()[:4000] # Keep it reasonably short for local models
    
    system_prompt = """
    You are an intelligent assistant for an IT support desk. Your task is to analyze incoming emails and classify their intent.
    You must respond ONLY with a valid JSON object and nothing else.

    Possible intents are:
    - 'new_request': An initial request to onboard a new user. Keywords: 'onboard', 'new user', 'access request'.
    - 'approval': An approval for a previous request. Keywords: 'approved', 'approve', 'ok to proceed'.
    - 'rejection': A rejection of a request. Keywords: 'rejected', 'denied'.
    - 'out_of_office': An automated out-of-office or vacation reply. Keywords: 'out of office', 'on vacation', 'limited access to email'.
    - 'query': A question or unrelated to onboarding.

    JSON Response Format:
    - For 'new_request', respond with: {"intent": "new_request", "user_email": "email@example.com"}
    - For 'out_of_office', respond with: {"intent": "out_of_office", "delegate_email": "delegate@example.com"}. If no delegate is mentioned, delegate_email must be null.
    - For all other intents, respond with: {"intent": "your_intent", "user_email": null, "delegate_email": null}
    """
    try:
        response = client.chat(
            model=config['OLLAMA_MODEL'],
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': full_content}
            ],
            options={
                'temperature': 0.0 # We want deterministic JSON output
            }
        )
        
        # The response from Ollama is in the 'content' field
        result_json_str = response['message']['content']
        
        # Clean up the response to ensure it's valid JSON
        cleaned_json_str = re.sub(r'^```json\s*|\s*```$', '', result_json_str, flags=re.MULTILINE).strip()

        logging.info(f"AI Analysis Result: {cleaned_json_str}")
        return json.loads(cleaned_json_str)

    except Exception as e:
        logging.error(f"Error calling Ollama: {e}", exc_info=True)
        return None