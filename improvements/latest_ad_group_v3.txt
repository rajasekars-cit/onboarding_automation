# FILE: run.py
# ==============================================================================
# Orchestrates multi-system onboarding workflow using thread pool.
# Producer enqueues active configs, workers dequeue and run processing.
# Implements shared mailbox polling + multi-dispatcher pattern.
# ==============================================================================

import time
import logging
import queue
import threading
from concurrent.futures import ThreadPoolExecutor
from app.main import run
from app.services import db_service
from app.config import get_static_config

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(threadName)s - %(module)s - %(message)s'
)

WORK_QUEUE = queue.Queue()

def worker_thread():
    logging.info("Worker thread started")
    while True:
        config = WORK_QUEUE.get()
        if config is None:
            logging.info("Worker received sentinel to shut down")
            break
        try:
            if 'all_configs' in config and 'static_config' in config:
                # Shared mailbox polling dispatcher task
                run(config['all_configs'], config['static_config'])
            else:
                logging.warning(f"Unknown or incomplete task received: {config}")
        except Exception as e:
            logging.error(f"Worker task error: {e}", exc_info=True)
        finally:
            WORK_QUEUE.task_done()

def producer_thread(static_config):
    while True:
        try:
            logging.info("Producer waking to schedule tasks")
            active_configs = db_service.get_all_active_configurations()
            if not active_configs:
                logging.info("No active configurations found")
            else:
                logging.info(f"Scheduling {len(active_configs)} active configurations")
                # Bundle static and dynamic configs for each config
                # For shared mailbox polling, combined into one task
                shared_mailbox_task = active_configs[0].copy()
                shared_mailbox_task['all_configs'] = active_configs
                shared_mailbox_task['static_config'] = static_config
                WORK_QUEUE.put(shared_mailbox_task)
            interval = static_config.get("SCHEDULE_MINUTES", 5) * 60
            time.sleep(interval)
        except Exception as e:
            logging.error(f"Producer thread error: {e}", exc_info=True)
            time.sleep(60)

if __name__ == "__main__":
    logging.info("Starting onboarding application with thread pool")
    static_cfg = get_static_config()
    max_workers = static_cfg.get("MAX_WORKER_THREADS", 10)

    db_service.setup_database()

    with ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="Worker") as executor:
        for _ in range(max_workers):
            executor.submit(worker_thread)

        producer = threading.Thread(target=producer_thread, args=(static_cfg,), name="Producer")
        producer.daemon = True
        producer.start()

        try:
            producer.join()
        except KeyboardInterrupt:
            logging.info("Shutdown requested, signaling workers to stop...")
            for _ in range(max_workers):
                WORK_QUEUE.put(None)

# FILE: app/config.py
# ==============================================================================
# Static configuration loader for environment variables
# ==============================================================================

import os
import logging
from dotenv import load_dotenv

load_dotenv()

def get_static_config():
    logging.info("Loading static configuration from environment variables")
    config = {}
    config['SCHEDULE_MINUTES'] = int(os.getenv("SCHEDULE_MINUTES", 5))
    config['MAX_WORKER_THREADS'] = int(os.getenv("MAX_WORKER_THREADS", 10))
    config['INITIAL_LOOKBACK_DAYS'] = int(os.getenv("INITIAL_LOOKBACK_DAYS", 1))
    config['REMINDER_THRESHOLD_HOURS'] = int(os.getenv("REMINDER_THRESHOLD_HOURS", 24))
    config['OLLAMA_HOST'] = os.getenv("OLLAMA_HOST", "http://localhost:11434")
    config['OLLAMA_MODEL'] = os.getenv("OLLAMA_MODEL", "llama3:8b")
    config['AZURE_TENANT_ID'] = os.getenv("AZURE_TENANT_ID")
    config['AZURE_CLIENT_ID'] = os.getenv("AZURE_CLIENT_ID")
    config['AZURE_CLIENT_SECRET'] = os.getenv("AZURE_CLIENT_SECRET")
    logging.info("Static configuration loaded.")
    return config

# FILE: app/main.py
# ==============================================================================
# Main onboarding workflow orchestration called by worker threads.
# ==============================================================================

import logging
from app.services.email_service import process_shared_mailbox_all_groups, process_pending_reminders

def run(all_configs, static_config):
    logging.info("Starting shared mailbox onboarding workflow cycle")

    try:
        process_shared_mailbox_all_groups(all_configs, static_config)
    except Exception as e:
        logging.error(f"Error during shared mailbox processing: {e}", exc_info=True)

    for cfg in all_configs:
        try:
            full_cfg = {**static_config, **cfg}
            process_pending_reminders(full_cfg)
        except Exception as e:
            logging.error(f"Error sending reminders for config {cfg.get('config_id')}: {e}", exc_info=True)

    logging.info("Completed onboarding workflow cycle")

# ==============================================================================
# FILE: app/services/ad_service.py
# ==============================================================================
# UPDATED: Fixed the MSAL token expiration error.
# ==============================================================================
import logging
import msal
import requests

GRAPH_API_ENDPOINT = 'https://graph.microsoft.com/v1.0'
_app_cache = {} # Cache the MSAL app object itself

def get_access_token(config):
    """Acquires an access token for the Microsoft Graph API, using MSAL's built-in caching."""
    tenant_id = config['AZURE_TENANT_ID']
    client_id = config['AZURE_CLIENT_ID']
    
    if not all([tenant_id, client_id, config.get('AZURE_CLIENT_SECRET')]):
        logging.error("Azure AD credentials (TENANT_ID, CLIENT_ID, CLIENT_SECRET) are not configured in .env file.")
        return None

    # Reuse the app object to leverage MSAL's internal token cache
    if client_id not in _app_cache:
        authority = f"https://login.microsoftonline.com/{tenant_id}"
        app = msal.ConfidentialClientApplication(
            client_id=client_id,
            authority=authority,
            client_credential=config['AZURE_CLIENT_SECRET'],
        )
        _app_cache[client_id] = app
    
    app = _app_cache[client_id]
    
    # acquire_token_for_client will automatically use its cache.
    # No need for manual expiration checks.
    token_result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])

    if "access_token" in token_result:
        return token_result["access_token"]
    else:
        logging.error(f"Failed to acquire Graph API token: {token_result.get('error_description')}")
        # Clear the app from cache in case of persistent auth failure
        if client_id in _app_cache:
            del _app_cache[client_id]
        return None

def get_user_id(user_email, token):
    """Gets the Azure AD object ID for a user from their email."""
    headers = {"Authorization": f"Bearer {token}"}
    params = {"$filter": f"mail eq '{user_email}' or userPrincipalName eq '{user_email}'"}
    response = requests.get(f"{GRAPH_API_ENDPOINT}/users", headers=headers, params=params)
    if response.status_code == 200:
        data = response.json().get("value")
        if data: return data[0]["id"]
    return None

def get_group_id(group_name, token):
    """Gets the Azure AD object ID for a group from its display name."""
    headers = {"Authorization": f"Bearer {token}"}
    params = {"$filter": f"displayName eq '{group_name}'"}
    response = requests.get(f"{GRAPH_API_ENDPOINT}/groups", headers=headers, params=params)
    if response.status_code == 200:
        data = response.json().get("value")
        if data: return data[0]["id"]
    return None

def is_user_in_group(user_email, group_name, config):
    """Checks if a user is a member of a specific Azure AD group."""
    token = get_access_token(config)
    if not token: return False
    group_id = get_group_id(group_name, token)
    if not group_id:
        logging.error(f"AD group '{group_name}' not found.")
        return False
    user_id = get_user_id(user_email, token)
    if not user_id:
        logging.warning(f"User '{user_email}' not found in AD for group check.")
        return False
    headers = {"Authorization": f"Bearer {token}"}
    json_payload = {"groupIds": [group_id]}
    response = requests.post(f"{GRAPH_API_ENDPOINT}/users/{user_id}/checkMemberGroups", headers=headers, json=json_payload)
    if response.status_code == 200:
        if group_id in response.json().get("value", []):
            logging.info(f"AD check PASSED: {user_email} is a member of '{group_name}'.")
            return True
    logging.warning(f"AD check FAILED: {user_email} is NOT a member of '{group_name}'.")
    return False

def get_user_manager(user_email, config):
    """Fetches the line manager's email for a given user from Azure AD."""
    token = get_access_token(config)
    if not token: return None
    # Step 1: Get the user's unique ID from their email address.
    user_id = get_user_id(user_email, token)
    if not user_id:
        logging.warning(f"Could not find user ID for '{user_email}'. Cannot fetch manager.")
        return None

    headers = {'Authorization': f'Bearer {token}'}
    # Step 2: Use the user_id in the API request, not the email.
    response = requests.get(f"{GRAPH_API_ENDPOINT}/users/{user_id}/manager", headers=headers)

    if response.status_code == 200:
        manager_data = response.json()
        manager_email = manager_data.get('mail')
        if manager_email:
            logging.info(f"Found manager for {user_email}: {manager_email}")
            return manager_email.lower()
    logging.warning(f"Could not fetch manager for {user_email}. Status: {response.status_code}, Body: {response.text}")
    return None

def get_group_owners(group_name, config):
    """Fetches the email addresses of the owners of a specific AD group."""
    token = get_access_token(config)
    if not token: return []
    group_id = get_group_id(group_name, token)
    if not group_id:
        logging.error(f"Cannot get owners because AD group '{group_name}' was not found.")
        return []
    headers = {'Authorization': f'Bearer {token}'}
    response = requests.get(f"{GRAPH_API_ENDPOINT}/groups/{group_id}/owners", headers=headers)
    if response.status_code == 200:
        owners_data = response.json().get("value", [])
        owner_emails = [owner.get('mail').lower() for owner in owners_data if owner.get('mail')]
        logging.info(f"Found owners for group '{group_name}': {owner_emails}")
        return owner_emails
    logging.error(f"Error fetching owners for group '{group_name}': {response.text}")
    return []

# FILE: app/services/email_service.py
# ==============================================================================
# Email parsing, shared mailbox polling, multi-config dispatch, request handling,
# approval, reminders, and email sending.
# ==============================================================================

import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import logging
import re
from datetime import datetime

from app.services import db_service, ad_service
from app.services.ai_service import analyze_email
UNMATCHED_APPROVALS = {}

AUTO_ADDRESS_PATTERNS = [
    r'no-?reply@', r'notification', r'do-?not-?reply@', r'mailer-daemon', r'postmaster@',
    r'automated', r'helpdesk', r'bounces@', r'^noreply', r'bot@', r'listserv',
    r'system@', r'alerts?@'
]

def is_autogenerated_address(email_address):
    if not email_address:
        return True
    return any(re.search(pat, email_address, re.IGNORECASE) for pat in AUTO_ADDRESS_PATTERNS)

ONBOARDING_KEYWORDS = [
    'onboard', 'request access', 'join', 'add access', 'add to group',
    'registration', 'enable access', 'new user', 'account setup',
    'provision', 'grant access', 'request membership', 'add user'
]

def contains_onboarding_keyword(text):
    return any(kw in text.lower() for kw in ONBOARDING_KEYWORDS)

def extract_email(from_header):
    if not from_header:
        return None
    match = re.search(r'<([^>]+)>', from_header)
    if match:
        return match.group(1).strip()
    match = re.search(r'[\w.\-+]+@[\w.\-]+', from_header)
    if match:
        return match.group(0).strip()
    if '@' in from_header and ' ' not in from_header:
        return from_header.strip()
    return None

def get_email_body(msg):
    if msg.is_multipart():
        for part in msg.walk():
            content_type = part.get_content_type()
            content_disp = str(part.get("Content-Disposition") or "")
            if content_type == "text/plain" and "attachment" not in content_disp.lower():
                try:
                    return part.get_payload(decode=True).decode()
                except Exception:
                    return part.get_payload(decode=True).decode('latin-1', errors='ignore')
    else:
        try:
            return msg.get_payload(decode=True).decode()
        except Exception:
            return msg.get_payload(decode=True).decode('latin-1', errors='ignore')
    return ""

def build_search_query(last_check_timestamp):
    search_date = datetime.fromisoformat(last_check_timestamp).strftime('%d-%b-%Y')
    return f'(SINCE "{search_date}")'

def send_email(recipients, subject, body, config):
    msg = MIMEMultipart()
    msg['From'] = f"{config['team_alias']} <{config['smtp_user']}>"
    msg['To'] = ", ".join(recipients)
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'plain'))
    try:
        with smtplib.SMTP(config['smtp_server'], config['smtp_port']) as server:
            server.starttls()
            server.login(config['smtp_user'], config['smtp_pass'])
            server.send_message(msg)
            logging.info(f"Sent email '{subject}' to {recipients}")
    except Exception as e:
        logging.error(f"Failed to send email '{subject}' to {recipients}: {e}", exc_info=True)

def build_group_config_map(config_list, static_config):
    """Return dict mapping uppercase required_ad_group -> merged config."""
    return {
        (c.get('required_ad_group') or '').upper(): {**static_config, **c}
        for c in config_list if c.get('required_ad_group')
    }

def process_shared_mailbox_all_groups(config_list, static_config):
    """
    Polls shared mailbox once, dispatches requests per requested_group
    to their respective configs (merged with static_config).
    """
    if not config_list:
        logging.warning("No configs provided for shared mailbox processing.")
        return

    shared_config = {**static_config, **config_list[0]}
    config_id = 'SHARED_MAILBOX'

    last_check_timestamp = db_service.get_last_check_time(config_id, shared_config)
    group_config_map = build_group_config_map(config_list, static_config)

    try:
        mail = imaplib.IMAP4_SSL(shared_config['imap_server'])
        mail.login(shared_config['imap_user'], shared_config['imap_pass'])
        mail.select("INBOX")

        search_query = build_search_query(last_check_timestamp)
        status, message_data = mail.uid('search', None, search_query)
        if status != "OK":
            logging.error(f"[{config_id}] IMAP search failed.")
            return

        all_uids = message_data[0].split()
        for uid in all_uids:
            uid_str = uid.decode() if isinstance(uid, bytes) else uid
            if not db_service.claim_uid_for_processing(uid_str):
                continue

            try:
                status, msg_parts = mail.uid('fetch', uid, '(RFC822)')
                if status != "OK" or not msg_parts or not msg_parts[0]:
                    continue

                msg = email.message_from_bytes(msg_parts[0][1])
                subject, encoding = decode_header(msg.get("Subject") or "")[0]
                if isinstance(subject, bytes):
                    subject = subject.decode(encoding or 'utf-8', errors='ignore')

                from_ = msg.get("From") or ""
                sender_email = extract_email(from_)
                if not sender_email:
                    logging.warning(f"[{config_id}] Could not extract sender email. Skipping UID {uid_str}.")
                    continue

                if is_autogenerated_address(sender_email):
                    logging.info(f"[{config_id}] Skipping automated/bot sender: {sender_email}")
                    continue

                body = get_email_body(msg)
                analysis = analyze_email(subject, body, shared_config)
                if not analysis:
                    logging.info(f"[{config_id}] LLM analysis failed / None for UID {uid_str}.")
                    continue

                intent = analysis.get('intent')
                user_email = analysis.get('user_email')
                
                if intent == 'new_request':
                    requested_group = (analysis.get('requested_group') or '').upper()
                    if not user_email or not requested_group:
                        logging.warning(f"[{config_id}] Missing user_email or requested_group in new request. Skipping UID {uid_str}.")
                        continue
                    target_config = group_config_map.get(requested_group)
                    if not target_config:
                        logging.warning(f"[{config_id}] No config found for group '{requested_group}'. Skipping UID {uid_str}.")
                        continue
                    logging.info(f"[{config_id}] Dispatching request for user '{user_email}' group '{requested_group}' to config '{target_config['config_id']}'.")
                    handle_onboarding_request(
                        user_email=user_email.lower(),
                        requested_group=requested_group,
                        config_id=target_config['config_id'],
                        sender_email=sender_email.lower(),
                        config=target_config
                    )
                elif intent == 'approval':
                    # === BEGIN FIX: Trust the database, not the AI for approvals ===
                    if not user_email:
                        logging.warning(f"[{config_id}] Missing user_email in approval. Skipping UID {uid_str}.")
                        continue
                    
                    # Find the active request using the user's email, which is more reliable.
                    active_request = db_service.find_active_request_by_user(user_email.lower())
                    
                    # === BEGIN FIX: Handle proactive approvals ===
                    if not active_request:
                        # No active request exists. Cache this approval temporarily.
                        logging.info(f"[{config_id}] Caching proactive approval from '{sender_email}' for user '{user_email}'.")
                        UNMATCHED_APPROVALS[user_email.lower()] = sender_email.lower()
                        continue # Move to the next email
                    # === END FIX ===
                    
                    # Use the correct group from the database record, not from the AI.
                    correct_requested_group = active_request['requested_group'].upper()
                    target_config = group_config_map.get(correct_requested_group)
                    
                    if not target_config:
                        logging.warning(f"[{config_id}] No config found for group '{correct_requested_group}' from active DB request. Skipping UID {uid_str}.")
                        continue
                    
                    logging.info(f"[{config_id}] Dispatching approval for user '{user_email}' group '{correct_requested_group}' to config '{target_config['config_id']}'.")
                    handle_approval_email(
                        from_email=sender_email.lower(),
                        user_email=user_email.lower(),
                        requested_group=correct_requested_group,
                        config=target_config
                    )
                    # === END FIX ===
                else:
                    logging.info(f"[{config_id}] Intent '{intent}' is not a new request or approval. Skipping UID {uid_str}.")

            except Exception as e:
                logging.error(f"[{config_id}] Exception processing UID {uid_str}: {e}", exc_info=True)

        mail.logout()
        db_service.update_last_check_time(config_id, datetime.now().isoformat())
    except Exception as e:
        logging.error(f"[{config_id}] Could not access mailbox: {e}", exc_info=True)

# -------------------------------------------------------------------------------
# Onboarding Request Handler (called per dispatched config)
# -------------------------------------------------------------------------------

def handle_onboarding_request(user_email, requested_group, config_id, sender_email, config):
    # This function remains unchanged.
    # 1. Check if user already has access
    if db_service.check_existing_access(user_email, config_id):
        logging.info(f"[{config_id}] User '{user_email}' already has access. Sending notification email.")
        send_already_onboarded_email(user_email, sender_email, config)
        return

    # 2. Check for existing active onboarding request
    active_req = db_service.get_active_request(user_email, requested_group, config_id)
    if active_req:
        db_service.create_duplicate_request(user_email, requested_group, config_id, duplicate_of=active_req['id'])
        logging.info(f"[{config_id}] Duplicate request for user '{user_email}', group '{requested_group}'. Informing sender.")
        send_duplicate_request_info_email(user_email, sender_email, config)
        return

    # 3. Determine sender role (self or manager)
    line_manager_email = ad_service.get_user_manager(user_email, config)
    if not line_manager_email:
        reason = f"Could not find the line manager for user '{user_email}'."
        logging.warning(f"[{config_id}] {reason}")
        send_rejection_email(sender_email, user_email, reason, config)
        return

    is_self_request = (sender_email == user_email)
    is_manager_request = (sender_email == line_manager_email.lower())

    if not (is_self_request or is_manager_request):
        reason = f"Request must be from user '{user_email}' or their line manager '{line_manager_email}'."
        logging.warning(f"[{config_id}] {reason} Sender: {sender_email}")
        send_rejection_email(sender_email, user_email, reason, config)
        return

    # 4. If manager request, verify membership & onboard immediately
    if is_manager_request:
        if not ad_service.is_user_in_group(user_email, requested_group, config):
            reason = f"User '{user_email}' is NOT a member of the AD group '{requested_group}'. Cannot onboard."
            logging.warning(f"[{config_id}] {reason}")
            send_rejection_email(sender_email, user_email, reason, config)
            return
        
        request_id = db_service.create_onboarding_request_composite(
            user_email, requested_group, config_id,
            status='pending_onboarding', current_stage=2,
            stage_approvals={'1': [sender_email]}  # Pre-approved by manager
        )
        logging.info(f"[{config_id}] Manager initiated immediate onboarding for user '{user_email}'.")
        db_service.onboard_user_to_target_db(user_email, config)
        db_service.update_request_status_composite(user_email, requested_group, config_id, 'completed', "Access granted by manager request.")
        send_confirmation_email(user_email, config)
        return

    # 5. Self-request: create request and send approval request to manager
    request_id = db_service.create_onboarding_request_composite(
        user_email, requested_group, config_id,
        status='pending_manager_approval', current_stage=1
    )

    # === BEGIN FIX: Check for and apply a cached proactive approval ===
    if user_email in UNMATCHED_APPROVALS:
        proactive_approver = UNMATCHED_APPROVALS.pop(user_email) # Use and remove from cache
        logging.info(f"[{config_id}] Found and applying cached approval from '{proactive_approver}' for user '{user_email}'.")
        # Call the approval handler directly to process the cached approval
        handle_approval_email(proactive_approver, user_email, requested_group, config)
        return # The approval handler will now manage the rest of the flow
    # === END FIX ===
    logging.info(f"[{config_id}] Self-request from user '{user_email}'. Sending manager approval request to '{line_manager_email}'.")
    send_manager_approval_request(user_email, requested_group, line_manager_email, config)


# -------------------------------------------------------------------------------
# Email Sending Helpers (unchanged)
# -------------------------------------------------------------------------------
def send_manager_approval_request(user_email, requested_group, manager_email, config):
    subject = f"Approval needed: Onboarding request for {user_email} to access {requested_group}"
    body = (
        f"Hello,\n\n"
        f"User '{user_email}' has submitted a request to be onboarded for access to '{requested_group}'.\n"
        f"Please reply with 'Approved' or 'Rejected'.\n\n"
        f"Thank you,\n{config['team_alias']}"
    )
    send_email([manager_email], subject, body, config)

def send_already_onboarded_email(user_email, sender_email, config):
    subject = f"Access Notification for {config['team_alias']}"
    body = (
        f"Hello,\n\n"
        f"Our records indicate that you ({user_email}) already have access to {config['team_alias']}.\n"
        f"If you have lost your password, please use the password reset flow.\n\n"
        f"Thank you.\n{config['team_alias']}"
    )
    send_email([sender_email], subject, body, config)

def send_duplicate_request_info_email(user_email, sender_email, config):
    subject = f"Duplicate Onboarding Request for {config['team_alias']}"
    body = (
        f"Hello,\n\n"
        f"We have received another onboarding request for user '{user_email}'.\n"
        f"Your earlier request is still being processed, so no duplicate processing is happening.\n"
        f"You will be notified once the request is complete.\n\n"
        f"Thank you.\n{config['team_alias']}"
    )
    send_email([sender_email], subject, body, config)

def send_rejection_email(recipient, rejected_user, reason, config):
    subject = f"Onboarding Request for {rejected_user} - Rejected"
    body = (
        f"Hello,\n\n"
        f"Your onboarding request was rejected for the following reason:\n{reason}\n\n"
        f"Please correct the issue and resubmit.\n\n"
        f"Thank you.\n{config['team_alias']}"
    )
    send_email([recipient], subject, body, config)

def send_confirmation_email(user_email, config):
    subject = f"Welcome! Your Access to {config['team_alias']} is Granted"
    body = (
        f"Hello,\n\n"
        f"Your account ({user_email}) has been successfully onboarded and granted access.\n\n"
        f"Best regards,\n{config['team_alias']}"
    )
    send_email([user_email], subject, body, config)

# -------------------------------------------------------------------------------
# Approval Processing (complete and integrated)
# -------------------------------------------------------------------------------
def handle_approval_email(from_email, user_email, requested_group, config):
    # This function remains unchanged.
    config_id = config['config_id']
    request = db_service.get_active_request(user_email, requested_group, config_id)
    if not request:
        logging.warning(f"[{config_id}] Approval received but no active request found for {user_email} / {requested_group}.")
        return

    if request['status'] == 'completed':
        logging.info(f"[{config_id}] Approval received for user {user_email} / {requested_group} but onboarding already completed. Ignoring.")
        return

    approver_email = extract_email(from_email).lower()
    effective_approvers = db_service.get_effective_approvers_for_stage(request, config)

    if approver_email not in effective_approvers:
        logging.warning(f"[{config_id}] Unauthorized approval attempt by {approver_email} for user {user_email}.")
        return

    approval_added = db_service.add_stage_approval(request, approver_email, config)
    if not approval_added:
        logging.info(f"[{config_id}] Approval by {approver_email} was already recorded for user {user_email}. Re-checking status.")

    request = db_service.get_active_request(user_email, requested_group, config_id)
    if not request:
        logging.error(f"[{config_id}] Failed to reload request for {user_email} after approval. Aborting.")
        return

    missing = db_service.get_missing_approvers_for_stage(request, config)
    if not missing:
        if request['current_stage'] >= 2:
            db_service.onboard_user_to_target_db(user_email, config)
            db_service.update_request_status_composite(user_email, requested_group, config_id, 'completed', 'Access granted after final approval.')
            send_confirmation_email(user_email, config)
            logging.info(f"[{config_id}] Onboarded user {user_email} for group {requested_group} after final approval.")
        else:
            advanced_request = db_service.advance_to_next_stage_composite(user_email, requested_group, config_id)
            if advanced_request:
                next_stage_missing = db_service.get_missing_approvers_for_stage(advanced_request, config)
                
                if not next_stage_missing:
                    logging.info(f"[{config_id}] Next stage for {user_email} is already approved. Advancing automatically.")
                    handle_approval_email(from_email, user_email, requested_group, config)
                else:
                    send_request_to_next_stage(advanced_request, config)
                    logging.info(f"[{config_id}] Advanced request for {user_email} to next stage after approval.")
            else:
                logging.error(f"[{config_id}] Failed to advance request stage for {user_email} / {requested_group}.")
    else:
        logging.info(f"[{config_id}] Approval from {approver_email} recorded. Still waiting on pending approvals from: {missing}")

# -------------------------------------------------------------------------------
# Reminder Emails
# -------------------------------------------------------------------------------
def process_pending_reminders(config):
    # This function remains unchanged.
    requests = []
    try:
        requests = db_service.get_pending_requests_for_reminder(config)
    except Exception as e:
        logging.error(f"[{config['config_id']}] Get pending reminders failed: {e}")

    for req in requests:
        missing_approvers = db_service.get_missing_approvers_for_stage(req, config)
        if not missing_approvers:
            continue
        subject = f"REMINDER: Approval Required for Onboarding {req['user_to_onboard_email']} ({req['requested_group']})"
        body = (
            f"Hello,\n\n"
            f"This is a reminder that your approval is still required for onboarding user "
            f"'{req['user_to_onboard_email']}' for group '{req['requested_group']}'.\n\n"
            f"Please review and respond to the original approval request email.\n\n"
            f"Thank you,\n{config['team_alias']}"
        )
        send_email(missing_approvers, subject, body, config)
        db_service.update_request_status_composite(
            req['user_to_onboard_email'], req['requested_group'], req['config_id'],
            req['status'], f"Reminder sent to: {', '.join(missing_approvers)}"
        )

# ==== Addendum: send_request_to_next_stage function used in approvals ==== #
def send_request_to_next_stage(request, config):
    # This function remains unchanged.
    current_stage_num = request['current_stage']
    user_to_onboard = request['user_to_onboard_email']
    team_alias = config.get('team_alias', config['config_id'])
    next_approvers = db_service.get_required_approvers_for_stage(request, config)
    
    stage_name = "Line Manager Approval" if current_stage_num == 1 else "System Owner Approval"
    
    if not next_approvers:
        db_service.update_request_status_composite(
            request['user_to_onboard_email'], request['requested_group'], request['config_id'], 
            'error', f"Could not find approvers for {stage_name}"
        )
        return
        
    subject = f"ACTION REQUIRED: [{team_alias}] Approval for Onboarding {user_to_onboard}"
    body = (
        f"Hello,\n\n"
        f"This onboarding request for user '{user_to_onboard}' for the '{team_alias}' system requires your approval.\n\n"
        f"Please reply to this email with 'Approved' or 'Rejected'.\n\n"
        f"Thank you,\n{config['team_alias']}"
    )
    
    send_email(next_approvers, subject, body, config)
    
    db_service.update_request_status_composite(
        request['user_to_onboard_email'], request['requested_group'], request['config_id'],
        f"pending_stage_{current_stage_num}_approval", f"Request sent to {stage_name} approvers."
    )

# FILE: app/services/db_service.py
# ==============================================================================
# Database interaction layer for user onboarding requests.
# Tracks requests by composite key (user_email, requested_group, config_id),
# supports multiple duplicates, statuses, approvals, delegated approvers.
# Also handles multi-db onboarding targets.
# ==============================================================================

import psycopg2
import logging
import json
import os
from psycopg2.extras import DictCursor
from datetime import datetime, timedelta
import mysql.connector
import oracledb
import pyodbc
from app.services import ad_service

def get_db_connection():
    try:
        return psycopg2.connect(
            dbname=os.getenv("DB_NAME"),
            user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASS"),
            host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT")
        )
    except Exception as e:
        logging.error(f"Failed to connect to DB: {e}")
        raise

def setup_database():
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            # Onboarding tracker with composite key and duplicate handling
            cur.execute("""
                CREATE TABLE IF NOT EXISTS onboarding_tracker (
                    id SERIAL PRIMARY KEY,
                    user_to_onboard_email VARCHAR(255) NOT NULL,
                    requested_group VARCHAR(100) NOT NULL,
                    config_id TEXT NOT NULL,
                    status VARCHAR(50) NOT NULL DEFAULT 'new',
                    current_stage INT DEFAULT 1,
                    stage_approvals JSONB DEFAULT '{}'::jsonb,
                    delegated_approvers JSONB DEFAULT '[]'::jsonb,
                    duplicate_of INTEGER,
                    request_count INT DEFAULT 1,
                    last_activity_details TEXT,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
                );
            """)
            cur.execute("""
                CREATE INDEX IF NOT EXISTS idx_onboard_email_group_config
                ON onboarding_tracker(user_to_onboard_email, requested_group, config_id);
            """)
            # Access log
            cur.execute("""
                CREATE TABLE IF NOT EXISTS onboarding_log (
                    email TEXT NOT NULL,
                    config_id TEXT NOT NULL,
                    access_flag BOOLEAN DEFAULT FALSE,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                    PRIMARY KEY (email, config_id)
                );
            """)
            # Processed UIDs to avoid reprocessing emails
            cur.execute("""
                CREATE TABLE IF NOT EXISTS processed_uids (
                    uid TEXT PRIMARY KEY,
                    processed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
                );
            """)
            # App state for global data like last timestamp
            cur.execute("""
                CREATE TABLE IF NOT EXISTS app_state (
                    key TEXT PRIMARY KEY,
                    value TEXT NOT NULL
                );
            """)
            # Configuration table, unchanged
            cur.execute("""
                CREATE TABLE IF NOT EXISTS configuration (
                    config_id TEXT PRIMARY KEY,
                    description TEXT,
                    is_active BOOLEAN DEFAULT TRUE,
                    team_alias TEXT NOT NULL,
                    imap_server TEXT NOT NULL,
                    imap_user TEXT NOT NULL,
                    imap_pass TEXT NOT NULL,
                    smtp_server TEXT NOT NULL,
                    smtp_port INT NOT NULL,
                    smtp_user TEXT NOT NULL,
                    smtp_pass TEXT NOT NULL,
                    workflow_type TEXT NOT NULL DEFAULT 'ad_validated',
                    required_ad_group TEXT,
                    target_db_type TEXT,
                    target_db_config JSONB,
                    target_table_name TEXT,
                    target_column_mappings JSONB
                );
            """)
            # Timestamp trigger on onboarding_tracker.updated_at
            cur.execute("""
                CREATE OR REPLACE FUNCTION trigger_set_timestamp()
                RETURNS TRIGGER AS $$
                BEGIN
                    NEW.updated_at = NOW();
                    RETURN NEW;
                END;
                $$ LANGUAGE plpgsql;
            """)
            cur.execute("""
                DROP TRIGGER IF EXISTS set_timestamp ON onboarding_tracker;
                CREATE TRIGGER set_timestamp
                BEFORE UPDATE ON onboarding_tracker
                FOR EACH ROW EXECUTE PROCEDURE trigger_set_timestamp();
            """)
            conn.commit()
            logging.info("Database setup completed.")
    except Exception as e:
        logging.error(f"Database setup error: {e}", exc_info=True)
    finally:
        if conn:
            conn.close()

# --- Access log ---

def check_existing_access(user_email, config_id):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            cur.execute("SELECT access_flag FROM onboarding_log WHERE email=%s AND config_id=%s;", (user_email, config_id))
            r = cur.fetchone()
            return bool(r and r[0])
    except Exception as e:
        logging.error(f"Error checking existing access: {e}")
        return False
    finally:
        if conn:
            conn.close()

def update_internal_user_access(user_email, config_id):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO onboarding_log (email, config_id, access_flag)
                VALUES (%s, %s, TRUE)
                ON CONFLICT (email, config_id) DO UPDATE SET access_flag=TRUE;
            """, (user_email, config_id))
            conn.commit()
            logging.info(f"Access updated for {user_email} on {config_id}")
    except Exception as e:
        logging.error(f"Failed to update internal access: {e}")
    finally:
        if conn: conn.close()

# --- Onboarding tracker (composite key) ---

def get_active_request(user_email, group, config_id):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("""
                SELECT * FROM onboarding_tracker
                WHERE user_to_onboard_email=%s AND requested_group=%s AND config_id=%s
                  AND status != 'completed'
                ORDER BY created_at DESC LIMIT 1;
            """, (user_email, group, config_id))
            return cur.fetchone()
    except Exception as e:
        logging.error(f"Failed fetching active request: {e}")
        return None
    finally:
        if conn:
            conn.close()

# === BEGIN FIX: Add the missing function ===
def find_active_request_by_user(user_email):
    """
    Finds the most recent, non-completed/non-duplicate request for a given user.
    This is used to reliably find a request when the AI analysis of an approval
    email might be ambiguous.
    """
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("""
                SELECT * FROM onboarding_tracker
                WHERE user_to_onboard_email = %s
                  AND status NOT IN ('completed', 'duplicate')
                ORDER BY updated_at DESC LIMIT 1;
            """, (user_email,))
            return cur.fetchone()
    except Exception as e:
        logging.error(f"Failed fetching active request by user '{user_email}': {e}")
        return None
    finally:
        if conn:
            conn.close()
# === END FIX ===

def create_onboarding_request_composite(user_email, group, config_id, status='pending_manager_approval', current_stage=1, stage_approvals=None):
    conn = None
    stage_approvals = stage_approvals or {}
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO onboarding_tracker (user_to_onboard_email, requested_group, config_id, status, current_stage, stage_approvals)
                VALUES (%s, %s, %s, %s, %s, %s)
                RETURNING id;
            """, (user_email, group, config_id, status, current_stage, json.dumps(stage_approvals)))
            conn.commit()
            return cur.fetchone()[0]
    except Exception as e:
        logging.error(f"Failed to create onboarding request: {e}")
        return None
    finally:
        if conn:
            conn.close()

def create_duplicate_request(user_email, group, config_id, duplicate_of):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO onboarding_tracker (user_to_onboard_email, requested_group, config_id, status, duplicate_of, request_count)
                VALUES (%s, %s, %s, 'duplicate', %s, 1);
            """, (user_email, group, config_id, duplicate_of))
            conn.commit()
    except Exception as e:
        logging.error(f"Failed to create duplicate request: {e}")
    finally:
        if conn:
            conn.close()

def update_request_status_composite(user_email, group, config_id, status, details):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            cur.execute("""
                UPDATE onboarding_tracker SET status=%s, last_activity_details=%s, updated_at=NOW()
                WHERE user_to_onboard_email=%s AND requested_group=%s AND config_id=%s AND status != 'duplicate';
            """, (status, details, user_email, group, config_id))
            conn.commit()
    except Exception as e:
        logging.error(f"Failed update request status: {e}")
    finally:
        if conn:
            conn.close()

def onboard_user_to_target_db(user_email, config):
    update_internal_user_access(user_email, config['config_id'])
    if not all([config.get('target_db_type'), config.get('target_table_name'), config.get('target_column_mappings')]):
        logging.warning(f"[{config['config_id']}] No target DB configured, skipping final onboarding.")
        return
    conn = None
    try:
        # connect to target DB based on config
        db_type = config['target_db_type']
        db_config = config['target_db_config']
        if db_type == 'postgresql':
            conn = psycopg2.connect(**db_config)
        elif db_type == 'mysql':
            conn = mysql.connector.connect(**db_config)
        elif db_type == 'oracle':
            conn = oracledb.connect(**db_config)
        elif db_type == 'mssql':
            conn_str = ';'.join([f'{k}={v}' for k,v in db_config.items()])
            conn = pyodbc.connect(conn_str)
        else:
            logging.error(f"Unsupported target DB type: {db_type}")
            return

        cursor = conn.cursor()
        table = config['target_table_name']
        mappings = config['target_column_mappings']

        email_col = mappings['email_column']

        # Use standard %s placeholder for psycopg2, which adapts it
        cursor.execute(f"SELECT {email_col} FROM {table} WHERE {email_col} = %s", (user_email,))
        exists = cursor.fetchone()

        default_values = {mappings[k.replace('default_', '') + '_column']: v for k,v in mappings.items() if k.startswith('default_')}

        if exists:
            update_cols = {**default_values, **{mappings['active_column']: True}}
            set_clause = ', '.join([f"{col} = %s" for col in update_cols.keys()])
            query = f"UPDATE {table} SET {set_clause} WHERE {email_col} = %s"
            params = list(update_cols.values()) + [user_email]
        else:
            insert_cols = {**default_values, **{mappings['email_column']: user_email, mappings['active_column']: True}}
            cols_clause = ', '.join(insert_cols.keys())
            placeholders = ', '.join(['%s'] * len(insert_cols))
            query = f"INSERT INTO {table} ({cols_clause}) VALUES ({placeholders})"
            params = list(insert_cols.values())

        cursor.execute(query, params)
        conn.commit()
        logging.info(f"User {user_email} onboarded in target table {table}")
    except Exception as e:
        logging.error(f"Onboarding to target DB failed: {e}", exc_info=True)
        if conn:
            conn.rollback()
    finally:
        if conn:
            conn.close()

def get_required_approvers_for_stage(request, config):
    stage = request['current_stage']
    if stage == 1:
        mgr = ad_service.get_user_manager(request['user_to_onboard_email'], config)
        return [mgr] if mgr else []
    elif stage == 2:
        return ad_service.get_group_owners(config['required_ad_group'], config)
    return []

def get_effective_approvers_for_stage(request, config):
    required = set(get_required_approvers_for_stage(request, config))
    delegations_raw = request.get('delegated_approvers', '[]')
    delegations = json.loads(delegations_raw) if isinstance(delegations_raw, str) else delegations_raw
    
    if not delegations:
        return list(required)
        
    mapping = {item['original']: item['delegate'] for item in delegations}
    effective = set()
    for approver in required:
        effective.add(mapping.get(approver, approver))
    return list(effective)

def get_missing_approvers_for_stage(request, config):
    effective = set(get_effective_approvers_for_stage(request, config))
    
    stage_approvals_raw = request.get('stage_approvals', {})
    stage_approvals = json.loads(stage_approvals_raw) if isinstance(stage_approvals_raw, str) else stage_approvals_raw
    
    approved = set(stage_approvals.get(str(request['current_stage']), []))
    return list(effective - approved)

def add_stage_approval(request, approver_email, config):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor(cursor_factory=DictCursor) as cur:
            stage_str = str(request['current_stage'])
            
            stage_approvals_raw = request.get('stage_approvals', {})
            stage_approvals = json.loads(stage_approvals_raw) if isinstance(stage_approvals_raw, str) else stage_approvals_raw
            
            current_approvals = stage_approvals.get(stage_str, [])
            if approver_email in current_approvals:
                return False # Already approved
            
            new_approvals = current_approvals + [approver_email]
            stage_approvals[stage_str] = new_approvals

            cur.execute("""
                UPDATE onboarding_tracker SET
                    stage_approvals = %s::jsonb,
                    last_activity_details = %s
                WHERE id = %s;
            """, (json.dumps(stage_approvals), f"Approval from {approver_email}", request['id']))
            
            conn.commit()
            return True # Successfully added
    except Exception as e:
        logging.error(f"Add stage approval failed: {e}")
        return False
    finally:
        if conn:
            conn.close()

def advance_to_next_stage_composite(user_email, group, config_id):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("""
                UPDATE onboarding_tracker SET current_stage = current_stage + 1, updated_at = NOW()
                WHERE user_to_onboard_email = %s AND requested_group = %s AND config_id = %s AND status NOT IN ('duplicate', 'completed')
                RETURNING *;
            """, (user_email, group, config_id))
            req = cur.fetchone()
            conn.commit()
            return req
    except Exception as e:
        logging.error(f"Failed advancing stage: {e}")
        return None
    finally:
        if conn:
            conn.close()

def get_pending_requests_for_reminder(config):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor(cursor_factory=DictCursor) as cur:
            reminder_hours = config.get('REMINDER_THRESHOLD_HOURS', 24)
            cur.execute("""
                SELECT * FROM onboarding_tracker
                WHERE status LIKE 'pending_%%'
                  AND updated_at < NOW() - INTERVAL '%s hours'
                  AND status NOT IN ('duplicate', 'completed');
            """, (reminder_hours,))
            return cur.fetchall()
    except Exception as e:
        logging.error(f"Get pending reminders failed: {e}")
        return []
    finally:
        if conn:
            conn.close()

def claim_uid_for_processing(uid):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            cur.execute("INSERT INTO processed_uids (uid) VALUES (%s) ON CONFLICT (uid) DO NOTHING;", (uid,))
            conn.commit()
            return cur.rowcount > 0
    except Exception as e:
        logging.error(f"Failed to claim UID {uid}: {e}")
        return False
    finally:
        if conn:
            conn.close()

def get_all_active_configurations():
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("SELECT * FROM configuration WHERE is_active = TRUE;")
            return cur.fetchall()
    except Exception as e:
        logging.error(f"Failed to get active configs: {e}")
        return []
    finally:
        if conn:
            conn.close()

def get_last_check_time(config_id, config):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            key = f"last_check_timestamp_{config_id}"
            cur.execute("SELECT value FROM app_state WHERE key = %s;", (key,))
            row = cur.fetchone()
            if row:
                return row[0]
            fallback = (datetime.now() - timedelta(days=config.get('INITIAL_LOOKBACK_DAYS',1))).isoformat()
            logging.info(f"[{config_id}] No last check timestamp, using fallback {fallback}")
            return fallback
    except Exception as e:
        logging.error(f"Failed to get last check timestamp: {e}")
        return (datetime.now() - timedelta(days=1)).isoformat()
    finally:
        if conn:
            conn.close()

def update_last_check_time(config_id, timestamp_iso):
    conn = None
    try:
        conn = get_db_connection()
        with conn.cursor() as cur:
            key = f"last_check_timestamp_{config_id}"
            cur.execute("""
                INSERT INTO app_state (key, value) VALUES (%s, %s)
                ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value;
            """, (key, timestamp_iso))
            conn.commit()
            logging.info(f"[{config_id}] Updated last check timestamp to {timestamp_iso}")
    except Exception as e:
        logging.error(f"Failed to update last check timestamp: {e}")
    finally:
        if conn:
            conn.close()

# ==============================================================================
# FILE: app/services/ai_service.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import logging
import json
import re
import ollama

client = None

# Helper regex for a "real" user email: must not be a no-reply/bot/etc email.
def is_real_user_email(email_address):
    if not email_address: return False
    patterns = [
        r'no-?reply@', r'notification', r'do-?not-?reply@', r'mailer-daemon',
        r'postmaster@', r'automated', r'helpdesk', r'bounces@',
        r'^noreply', r'bot@', r'listserv', r'system@', r'alerts?@'
    ]
    return not any(re.search(pat, email_address, re.IGNORECASE) for pat in patterns)

# Helper: Checks if onboarding "action" keywords are present in text
KEYWORDS = ['onboard', 'request access', 'join', 'add access', 'add to group', 'registration', 'enable access', 'new user', 'account setup', 'provision', 'grant access', 'request membership', 'add user']

def contains_onboarding_keyword(text):
    return any(kw in text.lower() for kw in KEYWORDS)

def analyze_email(subject, body, config):
    global client
    if client is None:
        logging.info(f"Initializing Ollama client with host: {config['OLLAMA_HOST']}")
        client = ollama.Client(host=config['OLLAMA_HOST'])

    full_content = f"Subject: {subject}\n\nBody:\n{body}"
    compacted = re.sub(r'\s+', ' ', full_content).strip()[:5000]
    
    # PROMPT UPGRADE
    system_prompt = """
You are a careful IT onboarding gatekeeper. Your job is to classify incoming emails.
You MUST ONLY return a JSON dictionary, and nothing else.

A "new_request" is valid ONLY when BOTH:
* The email expresses a clear onboarding intent (contains keywords like "onboard", "request access", "add user", "join", "add to group", "enable access", "registration"), AND
* Contains a real person's email address (NOT no-reply, notification, bot, mailer-daemon, etc).

If BOTH these conditions are not met, classify as intent "query" and set all extracted fields to null.

JSON format for output:

For onboarding requests:
  {
      "intent": "new_request",
      "user_email": "[REAL_EMAIL]",
      "requested_group": "[GROUP]" // The Team/System requested, e.g. "DEV". If you can't find it, set it to null.
  }

For everything else:
  {
    "intent": "query",
    "user_email": null,
    "delegate_email": null,
    "requested_group": null
  }
Do NOT guess or invent values. ONLY extract real emails from the body or subject and carefully check the sender.
If the only email present is a no-reply, notification, daemon, or other bot/system address, DO NOT create new_request.
Never use example.com or placeholder values.

For approvals and other flows: (same as before)
      {"intent": "[approval_or_rejection]", "user_email": "[USER]", "requested_group": "[GROUP_NAME]"}
      (if not found, use nulls)

If you see an out of office response that names a delegate, return:
      {"intent": "out_of_office", "delegate_email": "[DELEGATE_EMAIL]"}

REMEMBER:
* If the message does not contain onboarding keywords AND a real user email, classify as "query".
"""

    try:
        response = client.chat(
            model=config['OLLAMA_MODEL'],
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': compacted}
            ],
            options={'temperature': 0.0}
        )
        result_json_str = response['message']['content']
        cleaned_json_str = re.sub(r'^``````$', '', result_json_str, flags=re.MULTILINE).strip()

        # POST-CHECK: If onboarding, require at least 1 keyword in subject/body and real user email.
        res = json.loads(cleaned_json_str)
        user_email = res.get('user_email')
        # trust only if claim onboarding, has keyword, and is real user email
        if res.get('intent') == 'new_request':
            if not (is_real_user_email(user_email) and contains_onboarding_keyword(subject + ' ' + body)):
                res['intent'] = "query"
                res['user_email'] = None
                res['requested_group'] = None
        logging.info(f"AI Analysis Result: {json.dumps(res)}")
        return res

    except Exception as e:
        logging.error(f"Error calling Ollama: {e}", exc_info=True)
        return None

