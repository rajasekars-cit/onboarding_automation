# FILE: run.py
# ==============================================================================
# This file orchestrates the multi-system workflow using a thread pool.
# ==============================================================================
import time
import logging
import queue
import threading
from concurrent.futures import ThreadPoolExecutor
from app.main import run_onboarding_process
from app.services.db_service import setup_database, get_all_active_configurations
from app.config import get_static_config

# --- Basic Configuration ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(threadName)s - %(module)s - %(message)s')

# --- Thread Pool Configuration ---
WORK_QUEUE = queue.Queue()

def worker_thread():
    """The consumer function that each thread in the pool will run."""
    logging.info("Worker thread started and waiting for tasks.")
    while True:
        try:
            config = WORK_QUEUE.get()
            if config is None:  # Sentinel value to stop the thread
                break
            run_onboarding_process(config)
        except Exception as e:
            logging.error(f"Error in worker thread: {e}", exc_info=True)
        finally:
            WORK_QUEUE.task_done()

def producer_thread(static_config):
    """The producer function that runs on a schedule to check the DB and add tasks to the queue."""
    while True:
        try:
            logging.info("Producer thread waking up to schedule tasks...")
            active_configs = get_all_active_configurations()
            if not active_configs:
                logging.info("Producer found no active configurations.")
            else:
                logging.info(f"Producer found {len(active_configs)} active configurations to queue.")
                for dynamic_config in active_configs:
                    full_config = {**static_config, **dynamic_config}
                    WORK_QUEUE.put(full_config)
            
            schedule_interval_seconds = int(static_config.get('SCHEDULE_MINUTES', 5)) * 60
            time.sleep(schedule_interval_seconds)
        except Exception as e:
            logging.error(f"Error in producer thread: {e}", exc_info=True)
            time.sleep(60) # Wait a minute before retrying on error

if __name__ == "__main__":
    logging.info("Initializing multi-system onboarding application with Thread Pool...")
    
    static_config = get_static_config()
    MAX_WORKER_THREADS = static_config['MAX_WORKER_THREADS']
    
    setup_database()

    with ThreadPoolExecutor(max_workers=MAX_WORKER_THREADS, thread_name_prefix='Worker') as executor:
        for _ in range(MAX_WORKER_THREADS):
            executor.submit(worker_thread)

        producer = threading.Thread(target=producer_thread, args=(static_config,), name="Producer")
        producer.daemon = True
        producer.start()
        
        try:
            producer.join()
        except KeyboardInterrupt:
            logging.info("Application shutting down...")
            for _ in range(MAX_WORKER_THREADS):
                WORK_QUEUE.put(None)

# ==============================================================================
# FILE: app/config.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import os
import logging
from dotenv import load_dotenv

load_dotenv()

def get_static_config():
    """Loads global configuration from environment variables."""
    logging.info("Loading static configuration from .env file...")
    config = {}
    config['SCHEDULE_MINUTES'] = int(os.getenv("SCHEDULE_MINUTES", 5))
    config['MAX_WORKER_THREADS'] = int(os.getenv("MAX_WORKER_THREADS", 10))
    config['INITIAL_LOOKBACK_DAYS'] = int(os.getenv("INITIAL_LOOKBACK_DAYS", 1))
    config['REMINDER_THRESHOLD_HOURS'] = int(os.getenv("REMINDER_THRESHOLD_HOURS", 24))
    config['OLLAMA_HOST'] = os.getenv("OLLAMA_HOST", "http://localhost:11434")
    config['OLLAMA_MODEL'] = os.getenv("OLLAMA_MODEL", "llama3:8b")
    # MS Graph API credentials
    config['AZURE_TENANT_ID'] = os.getenv("AZURE_TENANT_ID")
    config['AZURE_CLIENT_ID'] = os.getenv("AZURE_CLIENT_ID")
    config['AZURE_CLIENT_SECRET'] = os.getenv("AZURE_CLIENT_SECRET")
    logging.info("Static configuration loaded successfully.")
    return config

# ==============================================================================
# FILE: app/main.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import logging
from app.services.email_service import process_mailbox, process_pending_reminders

def run_onboarding_process(config: dict):
    config_id = config.get('config_id', 'unknown')
    logging.info(f"--- [{config_id}] Starting job cycle ---")
    
    logging.info(f"--- [{config_id}] Step 1: Checking for new emails...")
    try:
        process_mailbox(config)
        logging.info(f"--- [{config_id}] Finished processing mailbox.")
    except Exception as e:
        logging.error(f"--- [{config_id}] An unexpected error occurred during mailbox processing: {e}", exc_info=True)
        
    logging.info(f"--- [{config_id}] Step 2: Checking for pending requests...")
    try:
        process_pending_reminders(config)
        logging.info(f"--- [{config_id}] Finished processing pending reminders.")
    except Exception as e:
        logging.error(f"--- [{config_id}] An unexpected error occurred during reminder processing: {e}", exc_info=True)

    logging.info(f"--- [{config_id}] Job cycle finished ---")

# ==============================================================================
# FILE: app/services/ad_service.py
# ==============================================================================
# UPDATED: Fixed the MSAL token expiration error.
# ==============================================================================
import logging
import msal
import requests

GRAPH_API_ENDPOINT = 'https://graph.microsoft.com/v1.0'
_app_cache = {} # Cache the MSAL app object itself

def get_access_token(config):
    """Acquires an access token for the Microsoft Graph API, using MSAL's built-in caching."""
    tenant_id = config['AZURE_TENANT_ID']
    client_id = config['AZURE_CLIENT_ID']
    
    if not all([tenant_id, client_id, config.get('AZURE_CLIENT_SECRET')]):
        logging.error("Azure AD credentials (TENANT_ID, CLIENT_ID, CLIENT_SECRET) are not configured in .env file.")
        return None

    # Reuse the app object to leverage MSAL's internal token cache
    if client_id not in _app_cache:
        authority = f"https://login.microsoftonline.com/{tenant_id}"
        app = msal.ConfidentialClientApplication(
            client_id=client_id,
            authority=authority,
            client_credential=config['AZURE_CLIENT_SECRET'],
        )
        _app_cache[client_id] = app
    
    app = _app_cache[client_id]
    
    # acquire_token_for_client will automatically use its cache.
    # No need for manual expiration checks.
    token_result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])

    if "access_token" in token_result:
        return token_result["access_token"]
    else:
        logging.error(f"Failed to acquire Graph API token: {token_result.get('error_description')}")
        # Clear the app from cache in case of persistent auth failure
        if client_id in _app_cache:
            del _app_cache[client_id]
        return None

def get_user_id(user_email, token):
    """Gets the Azure AD object ID for a user from their email."""
    headers = {"Authorization": f"Bearer {token}"}
    params = {"$filter": f"mail eq '{user_email}' or userPrincipalName eq '{user_email}'"}
    response = requests.get(f"{GRAPH_API_ENDPOINT}/users", headers=headers, params=params)
    if response.status_code == 200:
        data = response.json().get("value")
        if data: return data[0]["id"]
    return None

def get_group_id(group_name, token):
    """Gets the Azure AD object ID for a group from its display name."""
    headers = {"Authorization": f"Bearer {token}"}
    params = {"$filter": f"displayName eq '{group_name}'"}
    response = requests.get(f"{GRAPH_API_ENDPOINT}/groups", headers=headers, params=params)
    if response.status_code == 200:
        data = response.json().get("value")
        if data: return data[0]["id"]
    return None

def is_user_in_group(user_email, group_name, config):
    """Checks if a user is a member of a specific Azure AD group."""
    token = get_access_token(config)
    if not token: return False
    group_id = get_group_id(group_name, token)
    if not group_id:
        logging.error(f"AD group '{group_name}' not found.")
        return False
    user_id = get_user_id(user_email, token)
    if not user_id:
        logging.warning(f"User '{user_email}' not found in AD for group check.")
        return False
    headers = {"Authorization": f"Bearer {token}"}
    json_payload = {"groupIds": [group_id]}
    response = requests.post(f"{GRAPH_API_ENDPOINT}/users/{user_id}/checkMemberGroups", headers=headers, json=json_payload)
    if response.status_code == 200:
        if group_id in response.json().get("value", []):
            logging.info(f"AD check PASSED: {user_email} is a member of '{group_name}'.")
            return True
    logging.warning(f"AD check FAILED: {user_email} is NOT a member of '{group_name}'.")
    return False

def get_user_manager(user_email, config):
    """Fetches the line manager's email for a given user from Azure AD."""
    token = get_access_token(config)
    if not token: return None
    # Step 1: Get the user's unique ID from their email address.
    user_id = get_user_id(user_email, token)
    if not user_id:
        logging.warning(f"Could not find user ID for '{user_email}'. Cannot fetch manager.")
        return None

    headers = {'Authorization': f'Bearer {token}'}
    # Step 2: Use the user_id in the API request, not the email.
    response = requests.get(f"{GRAPH_API_ENDPOINT}/users/{user_id}/manager", headers=headers)

    if response.status_code == 200:
        manager_data = response.json()
        manager_email = manager_data.get('mail')
        if manager_email:
            logging.info(f"Found manager for {user_email}: {manager_email}")
            return manager_email.lower()
    logging.warning(f"Could not fetch manager for {user_email}. Status: {response.status_code}, Body: {response.text}")
    return None

def get_group_owners(group_name, config):
    """Fetches the email addresses of the owners of a specific AD group."""
    token = get_access_token(config)
    if not token: return []
    group_id = get_group_id(group_name, token)
    if not group_id:
        logging.error(f"Cannot get owners because AD group '{group_name}' was not found.")
        return []
    headers = {'Authorization': f'Bearer {token}'}
    response = requests.get(f"{GRAPH_API_ENDPOINT}/groups/{group_id}/owners", headers=headers)
    if response.status_code == 200:
        owners_data = response.json().get("value", [])
        owner_emails = [owner.get('mail').lower() for owner in owners_data if owner.get('mail')]
        logging.info(f"Found owners for group '{group_name}': {owner_emails}")
        return owner_emails
    logging.error(f"Error fetching owners for group '{group_name}': {response.text}")
    return []

# FILE: app/services/email_service.py
# ==============================================================================
# This service handles all email-related operations: reading, analyzing,
# routing, and sending emails for the onboarding workflow.
# ==============================================================================
import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import logging
import re
from datetime import datetime

from app.services import db_service, ad_service
from app.services.ai_service import analyze_email

# === Utility: Automated/bot sender and email detection ===
AUTO_ADDRESS_PATTERNS = [
    r'no-?reply@', r'notification', r'do-?not-?reply@', r'mailer-daemon', r'postmaster@',
    r'automated', r'helpdesk', r'bounces@', r'^noreply', r'bot@', r'listserv', r'system@', r'alerts?@'
]
def is_autogenerated_address(email_address):
    if not email_address:
        return True
    return any(re.search(pat, email_address, re.IGNORECASE) for pat in AUTO_ADDRESS_PATTERNS)

ONBOARDING_KEYWORDS = [
    'onboard', 'request access', 'join', 'add access', 'add to group',
    'registration', 'enable access', 'new user', 'account setup', 'provision', 'grant access', 'request membership', 'add user'
]
def contains_onboarding_keyword(text):
    t = text.lower()
    return any(kw in t for kw in ONBOARDING_KEYWORDS)

# (Optional) Restrict to allowlisted example domains:
# COMPANY_DOMAINS = ["yourcompany.com"]
# def is_allowed_domain(email_address):
#     if not email_address or "@" not in email_address: return False
#     domain = email_address.split("@")[1].lower()
#     return any(domain.endswith(a) for a in COMPANY_DOMAINS)

def extract_email(from_header):
    """Extracts an email address from a From: header."""
    match = re.search(r'<(.+?)>', from_header)
    if match:
        return match.group(1).strip()
    match = re.search(r'[\w.\-+]+@[\w.\-]+', from_header)
    if match:
        return match.group(0).strip()
    return from_header.strip() if '@' in from_header else None

def extract_thread_id(msg):
    """
    Extracts a reliable, single thread ID from email headers.
    Prioritizes 'In-Reply-To', then last in 'References', then 'Message-ID'.
    """
    if in_reply_to := msg.get('In-Reply-To'):
        return in_reply_to.strip()
    if references := msg.get('References'):
        return references.split()[-1].strip()
    return msg.get('Message-ID', '').strip()

def get_email_body(msg):
    """Extracts the text body from an email message."""
    if msg.is_multipart():
        for part in msg.walk():
            if part.get_content_type() == "text/plain" and "attachment" not in str(part.get("Content-Disposition")):
                try: return part.get_payload(decode=True).decode()
                except: return part.get_payload(decode=True).decode('latin-1')
    else:
        try: return msg.get_payload(decode=True).decode()
        except: return msg.get_payload(decode=True).decode('latin-1')
    return ""

def build_search_query(last_check_timestamp, config):
    """Builds a syntactically correct IMAP search query."""
    search_date = datetime.fromisoformat(last_check_timestamp).strftime('%d-%b-%Y')
    criteria = [f'(SINCE "{search_date}")']
    if imap_user := config.get('imap_user'):
        criteria.append(f'(OR (TO "{imap_user}") (CC "{imap_user}"))')
    return " ".join(criteria)

def send_email(recipients, subject, body, config, thread_id=None):
    """Generic function to send an email via SMTP, with optional threading."""
    msg = MIMEMultipart()
    msg['From'] = f"{config['team_alias']} <{config['smtp_user']}>"
    msg['To'] = ", ".join(recipients)
    msg['Subject'] = subject
    if thread_id:
        msg['In-Reply-To'] = thread_id
        msg['References'] = thread_id
    msg.attach(MIMEText(body, 'plain'))
    try:
        with smtplib.SMTP(config['smtp_server'], config['smtp_port']) as server:
            server.starttls()
            server.login(config['smtp_user'], config['smtp_pass'])
            server.send_message(msg)
            logging.info(f"Successfully sent email with subject '{subject}' to {recipients}")
    except Exception as e:
        logging.error(f"Failed to send email: {e}", exc_info=True)

# === MAIN WORKFLOW ===

def process_mailbox(config):
    """Main function to process the inbox for a given configuration, robustly."""
    config_id = config['config_id']
    last_check_timestamp = db_service.get_last_check_time(config_id, config)
    try:
        mail = imaplib.IMAP4_SSL(config['imap_server'])
        mail.login(config['imap_user'], config['imap_pass'])
        mail.select("inbox")
        search_criteria = build_search_query(last_check_timestamp, config)
        status, messages = mail.uid('search', None, search_criteria)
        if status != "OK":
            logging.error(f"[{config_id}] Failed to search for emails.")
            return
        all_uids = messages[0].split()
        for uid in all_uids:
            uid_str = uid.decode()
            if not db_service.claim_uid_for_processing(uid_str):
                continue
            try:
                status, msg_data = mail.uid('fetch', uid, "(RFC822)")
                if status != "OK": continue
                msg = email.message_from_bytes(msg_data[0][1])
                subject, _ = decode_header(msg["Subject"])[0]
                if isinstance(subject, bytes): subject = subject.decode()
                from_ = msg.get("From")
                body = get_email_body(msg)
                thread_id = extract_thread_id(msg)

                # --- NEW: Skip known bot/sender addresses upfront ---
                sender_email = extract_email(from_)
                if is_autogenerated_address(sender_email):
                    logging.info(f"[{config_id}] Skipping automated/bot/notification sender: {sender_email}")
                    continue

                # LLM/Pipeline intent
                analysis = analyze_email(subject, body, config)
                if not analysis: continue

                intent = analysis.get('intent')
                user_email = analysis.get('user_email')
                requested_group = analysis.get('requested_group')
                config_group = config.get('required_ad_group')

                # --- NEW: onboarding only if both: real, user (not bot), and keyword in msg ---
                if intent == "new_request":
                    # Optionally abort if not in business domain
                    # if not is_allowed_domain(user_email):
                    #     logging.info(f"[{config_id}] Skipping user not in allowed domains: {user_email}")
                    #     continue
                    if not (user_email and not is_autogenerated_address(user_email)):
                        logging.info(f"[{config_id}] Skipping onboarding: user_email looks auto/system: {user_email}")
                        continue
                    if not contains_onboarding_keyword(subject + " " + body):
                        logging.info(f"[{config_id}] Skipping onboarding: no keywords in text. subject='{subject}' body='{body[:60]}'")
                        continue

                if intent == 'new_request':
                    if requested_group and config_group and requested_group.upper() == config_group.upper():
                        handle_new_request(from_, analysis, thread_id, config)
                    elif requested_group is None:
                        handle_ambiguous_request(from_, analysis, thread_id, config)
                    else:
                        logging.info(f"[{config_id}] Request for '{requested_group}' does not match this config '{config_group}'. Ignoring.")
                elif intent == 'approval':
                    handle_approval(from_, thread_id, config)
                elif intent == 'out_of_office':
                    handle_out_of_office(from_, analysis, thread_id, config)
                # else: query/unknown, ignore
            except Exception as e:
                logging.error(f"[{config_id}] Error processing email UID {uid_str}: {e}", exc_info=True)
        mail.logout()
        db_service.update_last_check_time(config_id, datetime.now().isoformat())
    except Exception as e:
        logging.error(f"[{config_id}] Failed to connect to or process mailbox: {e}", exc_info=True)

# ==== REQUEST HANDLERS ==== 

def handle_new_request(from_email, analysis, thread_id, config):
    config_id = config['config_id']
    user_email = analysis.get('user_email')
    sender_email = extract_email(from_email)
    if not user_email:
        logging.warning(f"[{config_id}] New request received but no user email was extracted.")
        return
    if db_service.check_existing_access(user_email, config_id):
        send_already_onboarded_email(user_email, sender_email, thread_id, config)
        return
    required_group = config.get('required_ad_group')
    if required_group and not ad_service.is_user_in_group(user_email, required_group, config):
        reason = f"User '{user_email}' is not a member of the required AD group '{required_group}' for this system."
        send_rejection_email(sender_email, user_email, reason, thread_id, config)
        return

    line_manager_email = ad_service.get_user_manager(user_email, config)
    if not line_manager_email:
        reason = f"Could not verify the line manager for '{user_email}' in Active Directory."
        send_rejection_email(sender_email, user_email, reason, thread_id, config)
        return
    is_manager_request = sender_email.lower() == line_manager_email
    is_self_request = sender_email.lower() == user_email.lower()
    if is_self_request or is_manager_request:
        db_service.create_onboarding_request(thread_id, user_email, config_id)
        request = db_service.get_request_by_thread_id(thread_id)
        if not request:
            logging.error(f"[{config_id}] Failed to create or retrieve request for thread {thread_id}. Aborting.")
            return
    else:
        reason = f"The request was sent by '{sender_email}'. Requests must be initiated by the user ('{user_email}') or their line manager ('{line_manager_email}')."
        send_rejection_email(sender_email, user_email, reason, thread_id, config)
        return
    if is_self_request:
        logging.info(f"[{config_id}] New request from user '{user_email}'. Sending for line manager approval.")
        send_request_to_next_stage(request, config)
    elif is_manager_request:
        logging.info(f"[{config_id}] New request from line manager '{sender_email}'. Bypassing manager approval.")
        if db_service.add_stage_approval(request, line_manager_email, config):
            advanced_request = db_service.advance_to_next_stage(thread_id)
            send_request_to_next_stage(advanced_request, config)

def handle_ambiguous_request(from_email, analysis, thread_id, config):
    config_id = config['config_id']
    user_email = analysis.get('user_email')
    if not user_email: return
    if db_service.get_request_by_thread_id(thread_id):
        logging.info(f"[{config_id}] Clarification request for thread {thread_id} already being tracked. Ignoring.")
        return
    sender_email = extract_email(from_email)
    db_service.create_onboarding_request(thread_id, user_email, config_id, status='pending_clarification')
    send_clarification_email(sender_email, user_email, thread_id, config)

def handle_approval(from_email, thread_id, config):
    current_config_id = config['config_id']
    request = db_service.get_request_by_thread_id(thread_id)
    if not request:
        logging.warning(f"[{current_config_id}] Received an approval email but could not find a matching request for thread ID: {thread_id}. Skipping.")
        return
    request_config_id = request['config_id']
    if current_config_id != request_config_id:
        logging.info(f"[{current_config_id}] Ignoring approval for thread {thread_id} because it belongs to config '{request_config_id}'.")
        return
    logging.info(f"[{current_config_id}] Correctly processing approval for thread {thread_id}.")
    approver_email = extract_email(from_email)
    if approver_email not in db_service.get_effective_approvers_for_stage(request, config):
        logging.warning(f"[{current_config_id}] Received approval from unauthorized user: {approver_email} for thread {thread_id}")
        return
    if db_service.add_stage_approval(request, approver_email, config):
        user_to_onboard = request['user_to_onboard_email']
        if request['current_stage'] >= 2:
            db_service.onboard_user_to_target_db(user_to_onboard, config)
            db_service.update_request_status(thread_id, 'completed', f"Access granted for {user_to_onboard}.")
            send_confirmation_email(user_to_onboard, config)
        else:
            advanced_request = db_service.advance_to_next_stage(thread_id)
            send_request_to_next_stage(advanced_request, config)

def handle_out_of_office(from_email, analysis, thread_id, config):
    delegate_email = analysis.get('delegate_email')
    if not delegate_email: return
    request = db_service.get_request_by_thread_id(thread_id)
    if not request: return
    original_approver = extract_email(from_email)
    if original_approver in db_service.get_required_approvers_for_stage(request, config):
        db_service.add_delegated_approver(thread_id, delegate_email, original_approver)
        send_delegation_request_email(delegate_email, request, config)

# ==== EMAIL SENDERS ====

def send_request_to_next_stage(request, config):
    current_stage_num = request['current_stage']
    user_to_onboard = request['user_to_onboard_email']
    thread_id = request['request_thread_id']
    team_alias = config.get('team_alias', config['config_id'])
    next_approvers = db_service.get_required_approvers_for_stage(request, config)
    stage_name = "Line Manager Approval" if current_stage_num == 1 else "System Owner Approval"
    if not next_approvers:
        db_service.update_request_status(thread_id, 'error', f"Could not find approvers for {stage_name}")
        return
    subject = f"ACTION REQUIRED: [{team_alias}] Approval for Onboarding {user_to_onboard}"
    body = f"Hello,\n\nThis onboarding request for user '{user_to_onboard}' for the '{team_alias}' system requires your approval.\n\nPlease reply to this email with 'Approved' or 'Rejected'.\n\nThank you,\n{config['team_alias']}"
    send_email(next_approvers, subject, body, config, thread_id=thread_id)
    db_service.update_request_status(thread_id, f"pending_stage_{current_stage_num}_approval", f"Request sent to {stage_name} approvers.")

def send_clarification_email(recipient, user_email, thread_id, config):
    subject = f"ACTION REQUIRED: Clarification for Onboarding Request for {user_email}"
    body = f"Hello,\n\nWe have received your onboarding request for user '{user_email}'.\n\nTo proceed, please reply to this email specifying which system or team (e.g., DEV, DBA) access is needed for.\n\nThank you,\n{config['team_alias']}"
    send_email([recipient], subject, body, config, thread_id=thread_id)

def send_rejection_email(recipient, rejected_user, reason, thread_id, config):
    subject = f"Onboarding Request for {rejected_user} - Rejected"
    body = f"Hello,\n\nYour onboarding request for user '{rejected_user}' was rejected for the following reason:\n\n{reason}\n\nPlease correct the issue and resubmit.\n\nThank you,\n{config['team_alias']}"
    send_email([recipient], subject, body, config, thread_id=thread_id)

def send_already_onboarded_email(user_email, sender_email, thread_id, config):
    subject = f"Access Notification for {config['team_alias']}"
    body = f"Hello,\n\nOur records indicate that user '{user_email}' already has access. No further action is needed.\n\nBest regards,\n{config['team_alias']}"
    send_email([sender_email], subject, body, config, thread_id=thread_id)

def send_delegation_request_email(delegate_email, request, config):
    subject = f"ACTION REQUIRED: Delegated Approval for Onboarding {request['user_to_onboard_email']}"
    body = f"Hello,\n\nYou have been named as the delegate for an onboarding request for '{request['user_to_onboard_email']}'.\n\nPlease reply with 'Approved' or 'Rejected'.\n\nThank you,\n{config['team_alias']}"
    send_email([delegate_email], subject, body, config, thread_id=request['request_thread_id'])
    db_service.update_request_status(request['request_thread_id'], request['status'], f"Approval delegated to {delegate_email}.")

def send_confirmation_email(user_email, config):
    subject = f"Welcome! Your Access to {config['team_alias']} is Granted"
    body = f"Hello,\n\nThis is a confirmation that your account ({user_email}) has been successfully onboarded.\n\nBest regards,\n{config['team_alias']}"
    send_email([user_email], subject, body, config)

# ==== REMINDERS/UTILITIES ====

def process_pending_reminders(config):
    for request in db_service.get_pending_requests_for_reminder(config):
        send_reminder_email(request, config)

def send_reminder_email(request, config):
    user_to_onboard = request['user_to_onboard_email']
    thread_id = request['request_thread_id']
    missing_approvers = db_service.get_missing_approvers_for_stage(request, config)
    if not missing_approvers: return
    subject = f"REMINDER: Approval Required for Onboarding {user_to_onboard}"
    body = f"Hello,\n\nThis is a reminder that your approval is still required for the onboarding request for user: {user_to_onboard}.\n\nPlease reply to the original request with your approval.\n\nThank you,\n{config['team_alias']}"
    send_email(missing_approvers, subject, body, config, thread_id=thread_id)
    db_service.update_request_status(thread_id, request['status'], f"Reminder sent to: {', '.join(missing_approvers)}")

# FILE: app/services/db_service.py
# ==============================================================================
# This service handles all interactions with the bot's own PostgreSQL
# database and the target databases for onboarding.
# ==============================================================================
import psycopg2
import logging
import json
import os
from psycopg2.extras import DictCursor
from datetime import datetime, timedelta
import mysql.connector
import oracledb
import pyodbc
from app.services import ad_service

def get_db_connection():
    """Establishes a connection to the bot's own PostgreSQL database."""
    try:
        return psycopg2.connect(
            dbname=os.getenv("DB_NAME"), user=os.getenv("DB_USER"),
            password=os.getenv("DB_PASS"), host=os.getenv("DB_HOST"),
            port=os.getenv("DB_PORT")
        )
    except psycopg2.OperationalError as e:
        logging.error(f"Could not connect to PostgreSQL database: {e}"); raise

def setup_database():
    """Creates all necessary tables if they don't exist (non-destructive)."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                CREATE TABLE IF NOT EXISTS onboarding_log (
                    email TEXT NOT NULL,
                    config_id TEXT NOT NULL,
                    access_flag BOOLEAN DEFAULT FALSE,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                    PRIMARY KEY (email, config_id)
                );
            """)
            cur.execute("""
                CREATE TABLE IF NOT EXISTS onboarding_tracker (
                    id SERIAL PRIMARY KEY,
                    request_thread_id TEXT UNIQUE NOT NULL,
                    user_to_onboard_email VARCHAR(255),
                    config_id TEXT,
                    status VARCHAR(100) NOT NULL DEFAULT 'new',
                    current_stage INT DEFAULT 1,
                    stage_approvals JSONB DEFAULT '{}'::jsonb,
                    delegated_approvers JSONB DEFAULT '[]'::jsonb,
                    last_activity_details TEXT,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
                );
            """)
            cur.execute("CREATE TABLE IF NOT EXISTS app_state (key TEXT PRIMARY KEY, value TEXT NOT NULL);")
            cur.execute("CREATE TABLE IF NOT EXISTS processed_uids (uid TEXT PRIMARY KEY, processed_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP);")
            cur.execute("""
                CREATE TABLE IF NOT EXISTS configuration (
                    config_id TEXT PRIMARY KEY,
                    description TEXT,
                    is_active BOOLEAN DEFAULT TRUE,
                    team_alias TEXT NOT NULL,
                    imap_server TEXT NOT NULL,
                    imap_user TEXT NOT NULL,
                    imap_pass TEXT NOT NULL,
                    smtp_server TEXT NOT NULL,
                    smtp_port INT NOT NULL,
                    smtp_user TEXT NOT NULL,
                    smtp_pass TEXT NOT NULL,
                    workflow_type TEXT NOT NULL DEFAULT 'ad_validated',
                    required_ad_group TEXT,
                    target_db_type TEXT,
                    target_db_config JSONB,
                    target_table_name TEXT,
                    target_column_mappings JSONB
                );
            """)
            cur.execute("CREATE OR REPLACE FUNCTION trigger_set_timestamp() RETURNS TRIGGER AS $$ BEGIN NEW.updated_at = NOW(); RETURN NEW; END; $$ LANGUAGE plpgsql;")
            cur.execute("DROP TRIGGER IF EXISTS set_timestamp ON onboarding_tracker; CREATE TRIGGER set_timestamp BEFORE UPDATE ON onboarding_tracker FOR EACH ROW EXECUTE PROCEDURE trigger_set_timestamp();")
            conn.commit()
            logging.info("Database tables verified/created successfully.")
    except Exception as e: logging.error(f"Database setup failed: {e}")
    finally:
        if conn: conn.close()

def get_target_db_connection(config):
    """Establishes a connection to the target database specified in a configuration."""
    db_type = config.get('target_db_type')
    db_config = config.get('target_db_config')
    if not db_type or not db_config:
        raise ValueError("Target database configuration is missing.")
    logging.info(f"Connecting to target {db_type} database...")
    if db_type == 'postgresql':
        return psycopg2.connect(**db_config)
    elif db_type == 'mysql':
        return mysql.connector.connect(**db_config)
    elif db_type == 'oracle':
        return oracledb.connect(**db_config)
    elif db_type == 'mssql':
        conn_str = ';'.join([f'{k}={v}' for k, v in db_config.items()])
        return pyodbc.connect(conn_str)
    else:
        raise ValueError(f"Unsupported database type: {db_type}")

def onboard_user_to_target_db(user_email, config):
    """Grants a user access in a target system's database."""
    update_internal_user_access(user_email, config['config_id'])
    if not all([config.get('target_db_type'), config.get('target_table_name'), config.get('target_column_mappings')]):
        logging.warning(f"[{config['config_id']}] No target database configured. Skipping final onboarding step.")
        return
    conn = None
    try:
        conn = get_target_db_connection(config)
        cursor = conn.cursor()
        table = config['target_table_name']
        mappings = config['target_column_mappings']
        
        columns_to_set = {v: k.replace('_column', '') for k, v in mappings.items() if k.endswith('_column')}
        default_values = {mappings[k.replace('default_', '') + '_column']: v for k, v in mappings.items() if k.startswith('default_')}

        email_col = mappings['email_column']
        cursor.execute(f"SELECT {email_col} FROM {table} WHERE {email_col} = %s", (user_email,))
        exists = cursor.fetchone()

        if exists:
            update_cols = {**default_values, **{mappings['active_column']: True}}
            set_clause = ", ".join([f"{col} = %s" for col in update_cols.keys()])
            query = f"UPDATE {table} SET {set_clause} WHERE {email_col} = %s"
            params = list(update_cols.values()) + [user_email]
        else:
            insert_cols = {**default_values, **{mappings['email_column']: user_email, mappings['active_column']: True}}
            cols_clause = ", ".join(insert_cols.keys())
            placeholders = ", ".join(["%s"] * len(insert_cols))
            query = f"INSERT INTO {table} ({cols_clause}) VALUES ({placeholders})"
            params = list(insert_cols.values())
        
        cursor.execute(query, params)
        conn.commit()
        logging.info(f"Successfully onboarded {user_email} in target table '{table}'.")
    except Exception as e:
        logging.error(f"Failed to onboard user in target database: {e}", exc_info=True)
        if conn: conn.rollback()
    finally:
        if conn: conn.close()

def get_all_active_configurations():
    """Retrieves all active system configurations from the database."""
    conn = get_db_connection()
    configs = []
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("SELECT * FROM configuration WHERE is_active = TRUE;")
            for row in cur.fetchall():
                configs.append(dict(row))
    except Exception as e:
        logging.error(f"Could not load active configurations from database: {e}", exc_info=True)
    finally:
        if conn: conn.close()
    return configs

def get_required_approvers_for_stage(request, config):
    """Determines the required approvers for a request's current stage."""
    current_stage_num = request['current_stage']
    if current_stage_num == 1:
        manager = ad_service.get_user_manager(request['user_to_onboard_email'], config)
        return [manager] if manager else []
    elif current_stage_num == 2:
        return ad_service.get_group_owners(config['required_ad_group'], config)
    return []

def get_effective_approvers_for_stage(request, config):
    """Determines the effective approvers, considering delegations."""
    required_approvers = set(get_required_approvers_for_stage(request, config))
    delegations = request.get('delegated_approvers', [])
    if not delegations:
        return required_approvers
    delegation_map = {item['original']: item['delegate'] for item in delegations}
    effective_set = set()
    for approver in required_approvers:
        if approver in delegation_map:
            effective_set.add(delegation_map[approver])
        else:
            effective_set.add(approver)
    return effective_set

def get_missing_approvers_for_stage(request, config):
    """Returns a list of approvers who have not yet approved the current stage."""
    effective_approvers = get_effective_approvers_for_stage(request, config)
    received_approvals = set(request['stage_approvals'].get(str(request['current_stage']), []))
    return list(effective_approvers - received_approvals)

def add_delegated_approver(thread_id, delegate_email, original_approver):
    """Adds a delegated approver to a request."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            delegation_map = {"original": original_approver, "delegate": delegate_email}
            cur.execute("UPDATE onboarding_tracker SET delegated_approvers = delegated_approvers || %s::jsonb WHERE request_thread_id = %s;", (json.dumps(delegation_map), thread_id))
            conn.commit()
            logging.info(f"Added {delegate_email} as a delegated approver for {original_approver} on thread {thread_id}")
    except Exception as e: logging.error(f"Failed to add delegated approver for thread {thread_id}: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def add_stage_approval(request, approver_email, config):
    """Adds an approval to the current stage and returns if the stage is complete."""
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            current_stage_num = request['current_stage']
            current_stage_str = str(current_stage_num)
            cur.execute("""
                UPDATE onboarding_tracker
                SET stage_approvals = jsonb_set(
                    stage_approvals, ARRAY[%s],
                    (COALESCE(stage_approvals->%s, '[]'::jsonb) || %s::jsonb) - %s || %s::jsonb
                ),
                last_activity_details = %s
                WHERE request_thread_id = %s RETURNING *;
            """, (current_stage_str, current_stage_str, json.dumps(approver_email), json.dumps(approver_email), json.dumps(approver_email), f"Approval for stage {current_stage_str} received from {approver_email}", request['request_thread_id']))
            updated_request = cur.fetchone()
            conn.commit()
            if not updated_request: return False
            missing_approvers = get_missing_approvers_for_stage(updated_request, config)
            return not missing_approvers
    except Exception as e:
        logging.error(f"Failed to add stage approval: {e}", exc_info=True)
        return False
    finally:
        if conn: conn.close()

def advance_to_next_stage(thread_id):
    """Advances a request to the next stage."""
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("UPDATE onboarding_tracker SET current_stage = current_stage + 1 WHERE request_thread_id = %s RETURNING *;", (thread_id,))
            request = cur.fetchone()
            conn.commit()
            return request
    finally:
        if conn: conn.close()

def check_existing_access(user_email, config_id):
    """Checks if a user already has access according to the internal log."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT access_flag FROM onboarding_log WHERE email = %s AND config_id = %s;", (user_email, config_id))
            result = cur.fetchone()
            return result[0] if result and result[0] else False
    except Exception as e:
        logging.error(f"Failed to check existing access for {user_email}: {e}", exc_info=True)
        return False
    finally:
        if conn: conn.close()

def create_onboarding_request(thread_id, user_email, config_id, status='pending_stage_1_approval'):
    """Creates or updates an onboarding request in the tracker."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            details = "Awaiting clarification from sender." if status == 'pending_clarification' else f"New onboarding request received for {user_email}."
            
            cur.execute("""
                INSERT INTO onboarding_tracker (request_thread_id, user_to_onboard_email, config_id, status, last_activity_details) 
                VALUES (%s, %s, %s, %s, %s) 
                ON CONFLICT (request_thread_id) DO UPDATE SET
                    status = EXCLUDED.status,
                    last_activity_details = EXCLUDED.last_activity_details,
                    config_id = EXCLUDED.config_id
                WHERE onboarding_tracker.status = 'pending_clarification';
            """, (thread_id, user_email, config_id, status, details))
            
            conn.commit()
            if cur.rowcount > 0:
                logging.info(f"Onboarding request for {user_email} (Thread: {thread_id[:15]}...) created or updated with status '{status}'")
            else:
                logging.info(f"Onboarding request for thread ID {thread_id[:15]}... already exists and is not pending clarification.")
    except Exception as e:
        logging.error(f"Failed to create/update onboarding request: {e}", exc_info=True)
    finally:
        if conn: conn.close()


def update_internal_user_access(user_email, config_id):
    """Updates the bot's own tracking table for user access."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO onboarding_log (email, config_id, access_flag)
                VALUES (%s, %s, TRUE)
                ON CONFLICT (email, config_id) DO UPDATE SET access_flag = TRUE;
            """, (user_email, config_id))
            conn.commit()
            logging.info(f"Successfully updated internal access tracking for user {user_email} to system {config_id}")
    except Exception as e:
        logging.error(f"Failed to update internal user access for {user_email}: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def get_last_check_time(config_id, config):
    """Gets the timestamp of the last successful email check for a configuration."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            state_key = f"last_check_timestamp_{config_id}"
            cur.execute("SELECT value FROM app_state WHERE key = %s;", (state_key,))
            result = cur.fetchone()
            if result: return result[0]
            else:
                initial_time = (datetime.now() - timedelta(days=config['INITIAL_LOOKBACK_DAYS'])).isoformat()
                logging.info(f"[{config_id}] No last check timestamp found in DB. Using initial lookback: {initial_time}")
                return initial_time
    except Exception as e:
        logging.error(f"Failed to get last check time for {config_id}: {e}", exc_info=True)
        return (datetime.now() - timedelta(days=1)).isoformat()
    finally:
        if conn: conn.close()

def update_last_check_time(config_id, timestamp_iso):
    """Updates the timestamp of the last successful email check."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            state_key = f"last_check_timestamp_{config_id}"
            cur.execute("INSERT INTO app_state (key, value) VALUES (%s, %s) ON CONFLICT (key) DO UPDATE SET value = EXCLUDED.value;", (state_key, timestamp_iso))
            conn.commit()
            logging.info(f"[{config_id}] Updated last check timestamp to: {timestamp_iso}")
    except Exception as e: logging.error(f"Failed to update last check time for {config_id}: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def get_pending_requests_for_reminder(config):
    """Gets all requests that are pending for longer than the reminder threshold."""
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            query = "SELECT * FROM onboarding_tracker WHERE status LIKE 'pending_stage%%' AND updated_at < NOW() - INTERVAL '%s hours'"
            cur.execute(query, (config['REMINDER_THRESHOLD_HOURS'],))
            return cur.fetchall()
    except Exception as e:
        logging.error(f"Failed to get pending requests: {e}", exc_info=True)
        return []
    finally:
        if conn: conn.close()

def get_request_by_thread_id(thread_id):
    """Retrieves a single request from the database by its thread ID."""
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=DictCursor) as cur:
            cur.execute("SELECT * FROM onboarding_tracker WHERE request_thread_id = %s;", (thread_id,))
            return cur.fetchone()
    except Exception as e:
        logging.error(f"Failed to get request for thread {thread_id}: {e}", exc_info=True)
        return None
    finally:
        if conn: conn.close()

def update_request_status(thread_id, status, details):
    """Updates the status and activity details of a request."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("UPDATE onboarding_tracker SET status = %s, last_activity_details = %s WHERE request_thread_id = %s;", (status, details, thread_id))
            conn.commit()
            logging.info(f"Updated status for thread {thread_id[:15]}... to '{status}'")
    except Exception as e: logging.error(f"Failed to update request status: {e}", exc_info=True)
    finally:
        if conn: conn.close()

def get_processed_uids(uids_to_check):
    """Checks a list of UIDs against the database to see which have been processed."""
    if not uids_to_check: return set()
    uids_to_check_str = [uid.decode() if isinstance(uid, bytes) else uid for uid in uids_to_check]
    conn = get_db_connection()
    processed_uids = set()
    try:
        with conn.cursor() as cur:
            cur.execute("SELECT uid FROM processed_uids WHERE uid = ANY(%s);", (uids_to_check_str,))
            for row in cur.fetchall(): processed_uids.add(row[0])
    except Exception as e: logging.error(f"Failed to get processed UIDs: {e}", exc_info=True)
    finally:
        if conn: conn.close()
    return processed_uids

def mark_uid_as_processed(uid):
    """Marks an email UID as processed to prevent re-reading."""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("INSERT INTO processed_uids (uid) VALUES (%s) ON CONFLICT (uid) DO NOTHING;", (uid,))
            conn.commit()
    except Exception as e: logging.error(f"Failed to mark UID {uid} as processed: {e}", exc_info=True)
    finally:
        if conn: conn.close()

# --- Add this new function to the file ---
def claim_uid_for_processing(uid):
    """
    Atomically inserts a UID to claim it for processing.
    Returns True if the claim was successful (row was inserted), False otherwise.
    """
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("INSERT INTO processed_uids (uid) VALUES (%s) ON CONFLICT (uid) DO NOTHING;", (uid,))
            conn.commit()
            # rowcount will be 1 if the INSERT succeeded, 0 if it hit a conflict.
            return cur.rowcount > 0
    except Exception as e:
        logging.error(f"Failed to claim UID {uid}: {e}", exc_info=True)
        return False # Assume failure on error
    finally:
        if conn: conn.close()

# ==============================================================================
# FILE: app/services/ai_service.py
# ==============================================================================
# This file is unchanged.
# ==============================================================================
import logging
import json
import re
import ollama

client = None

# Helper regex for a "real" user email: must not be a no-reply/bot/etc email.
def is_real_user_email(email_address):
    if not email_address: return False
    patterns = [
        r'no-?reply@', r'notification', r'do-?not-?reply@', r'mailer-daemon',
        r'postmaster@', r'automated', r'helpdesk', r'bounces@',
        r'^noreply', r'bot@', r'listserv', r'system@', r'alerts?@'
    ]
    return not any(re.search(pat, email_address, re.IGNORECASE) for pat in patterns)

# Helper: Checks if onboarding "action" keywords are present in text
KEYWORDS = ['onboard', 'request access', 'join', 'add access', 'add to group', 'registration', 'enable access', 'new user', 'account setup', 'provision', 'grant access', 'request membership', 'add user']

def contains_onboarding_keyword(text):
    return any(kw in text.lower() for kw in KEYWORDS)

def analyze_email(subject, body, config):
    global client
    if client is None:
        logging.info(f"Initializing Ollama client with host: {config['OLLAMA_HOST']}")
        client = ollama.Client(host=config['OLLAMA_HOST'])

    full_content = f"Subject: {subject}\n\nBody:\n{body}"
    compacted = re.sub(r'\s+', ' ', full_content).strip()[:5000]
    
    # PROMPT UPGRADE
    system_prompt = """
You are a careful IT onboarding gatekeeper. Your job is to classify incoming emails.
You MUST ONLY return a JSON dictionary, and nothing else.

A "new_request" is valid ONLY when BOTH:
* The email expresses a clear onboarding intent (contains keywords like "onboard", "request access", "add user", "join", "add to group", "enable access", "registration"), AND
* Contains a real person's email address (NOT no-reply, notification, bot, mailer-daemon, etc).

If BOTH these conditions are not met, classify as intent "query" and set all extracted fields to null.

JSON format for output:

For onboarding requests:
  {
      "intent": "new_request",
      "user_email": "[REAL_EMAIL]",
      "requested_group": "[GROUP]" // The Team/System requested, e.g. "DEV". If you can't find it, set it to null.
  }

For everything else:
  {
    "intent": "query",
    "user_email": null,
    "delegate_email": null,
    "requested_group": null
  }
Do NOT guess or invent values. ONLY extract real emails from the body or subject and carefully check the sender.
If the only email present is a no-reply, notification, daemon, or other bot/system address, DO NOT create new_request.
Never use example.com or placeholder values.

For approvals and other flows: (same as before)
      {"intent": "[approval_or_rejection]", "user_email": "[USER]", "requested_group": "[GROUP_NAME]"}
      (if not found, use nulls)

If you see an “out of office” response that names a delegate, return:
      {"intent": "out_of_office", "delegate_email": "[DELEGATE_EMAIL]"}

REMEMBER:
* If the message does not contain onboarding keywords AND a real user email, classify as "query".
"""

    try:
        response = client.chat(
            model=config['OLLAMA_MODEL'],
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': compacted}
            ],
            options={'temperature': 0.0}
        )
        result_json_str = response['message']['content']
        cleaned_json_str = re.sub(r'^``````$', '', result_json_str, flags=re.MULTILINE).strip()

        # POST-CHECK: If onboarding, require at least 1 keyword in subject/body and real user email.
        res = json.loads(cleaned_json_str)
        user_email = res.get('user_email')
        # trust only if claim onboarding, has keyword, and is real user email
        if res.get('intent') == 'new_request':
            if not (is_real_user_email(user_email) and contains_onboarding_keyword(subject + ' ' + body)):
                res['intent'] = "query"
                res['user_email'] = None
                res['requested_group'] = None
        logging.info(f"AI Analysis Result: {json.dumps(res)}")
        return res

    except Exception as e:
        logging.error(f"Error calling Ollama: {e}", exc_info=True)
        return None
